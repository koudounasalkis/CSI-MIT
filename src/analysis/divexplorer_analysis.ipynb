{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db905f0a",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-information",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T15:20:44.908897Z",
     "start_time": "2022-04-20T15:20:44.883774Z"
    },
    "id": "powered-information"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-doctor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T15:20:45.349495Z",
     "start_time": "2022-04-20T15:20:44.910825Z"
    },
    "id": "built-doctor"
   },
   "outputs": [],
   "source": [
    "import divexplorer \n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None)\n",
    "import os\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from utils_analysis import plotMultipleSV, plotShapleyValue\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c80058f0",
   "metadata": {},
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26247e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for sorting data cohorts\n",
    "def sortItemset(x, abbreviations={}):\n",
    "    x = list(x)\n",
    "    x.sort()\n",
    "    x = \", \".join(x)\n",
    "    for k, v in abbreviations.items():\n",
    "        x = x.replace(k, v)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e539fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attributes_in_itemset(itemset, attributes, alls = True):\n",
    "    \"\"\" Check if attributes are in the itemset (all or at least one)\n",
    "    \n",
    "    Args:\n",
    "        itemset (frozenset): the itemset\n",
    "        attributes (list): list of itemset of interest\n",
    "        alls (bool): If True, check if ALL attributes of the itemset are the input attributes. \n",
    "        If False, check AT LEAST one attribute of the itemset is in the input attributes.\n",
    "        \n",
    "    \"\"\"\n",
    "    # Avoid returning the empty itemset (i.e., info of entire dataset)\n",
    "    if itemset == frozenset() and attributes:\n",
    "        return False\n",
    "    \n",
    "    for item in itemset:\n",
    "        # Get the attribute\n",
    "        attr_i = item.split(\"=\")[0]\n",
    "        \n",
    "        #If True, check if ALL attributes of the itemset are the input attributes.\n",
    "        if alls:\n",
    "            # Check if the attribute is present. If not, the itemset is not admitted\n",
    "            if attr_i not in attributes:\n",
    "                return False\n",
    "        else:\n",
    "            # Check if least one attribute. If yes, return True\n",
    "            if attr_i in attributes:\n",
    "                return True\n",
    "    if alls:\n",
    "        # All attributes of the itemset are indeed admitted\n",
    "        return True\n",
    "    else:\n",
    "        # Otherwise, it means that we find None\n",
    "        return False\n",
    "    \n",
    "def filter_itemset_df_by_attributes(df: pd.DataFrame, attributes: list, alls = True, itemset_col_name: str = \"itemsets\") -> pd.DataFrame:\n",
    "    \"\"\"Get the set of itemsets that have the attributes in the input list (all or at least one)\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): the input itemsets (with their info). \n",
    "        attributes (list): list of itemset of interest\n",
    "        alls (bool): If True, check if ALL attributes of the itemset are the input attributes. \n",
    "        If False, check AT LEAST one attribute of the itemset is in the input attributes.\n",
    "        itemset_col_name (str) : the name of the itemset column, \"itemsets\" as default\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: the set of itemsets (with their info)\n",
    "    \"\"\"\n",
    "\n",
    "    return df.loc[df[itemset_col_name].apply(lambda x: attributes_in_itemset(x, attributes, alls = alls))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d02de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define abbreviations for plot and visualization\n",
    "from divexplorer.FP_Divergence import abbreviateDict\n",
    "abbreviations = {'Self-reported fluency level=native': 'fluency=native', \\\n",
    "                  'total_silence':'tot_silence', 'location': 'loc', \\\n",
    "                  'Current language used for work/school=English (United States)': 'lang=EN_US', \\\n",
    "                  'ageRange': 'age', \\\n",
    "                  'speakerId' : 'spkID', \\\n",
    "                  'First Language spoken=English (United States)':  'lang=EN_US', \\\n",
    "                  'trimmed': 'trim', \\\n",
    "                  'total_': 'tot_', \\\n",
    "                  'speed_rate_word':'speakRate', \\\n",
    "                  'speed_rate_char':'speakCharRate', \\\n",
    "                  'change language': 'change lang', \\\n",
    "                  'duration': 'dur'}\n",
    "\n",
    "abbreviations_shorter = abbreviations.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "occupational-madrid",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-20T15:07:23.652910Z",
     "start_time": "2022-04-20T15:07:23.612488Z"
    },
    "id": "occupational-madrid"
   },
   "source": [
    "# Define targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461193a2",
   "metadata": {
    "id": "461193a2"
   },
   "outputs": [],
   "source": [
    "## Target for DivExplorer: \n",
    "# 'prediction' is 1 if predicted_intet == original_intent, 0 otherwise\n",
    "target_col = 'prediction' \n",
    "target_metric = 'd_posr'\n",
    "target_div = 'd_accuracy'\n",
    "t_value_col = 't_value_tp_fn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa3b44",
   "metadata": {
    "id": "8efa3b44"
   },
   "outputs": [],
   "source": [
    "## Columns for visualization\n",
    "show_cols = ['support', 'itemsets', '#errors', '#corrects', 'accuracy', \\\n",
    "                'd_accuracy', 't_value', 'support_count', 'length']\n",
    "remapped_cols = {'tn': '#errors', 'tp': '#corrects', 'posr': 'accuracy', \\\n",
    "                target_metric: target_div, 't_value_tp_fn': 't_value'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bbd447",
   "metadata": {},
   "source": [
    "# FSC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e257bab",
   "metadata": {},
   "source": [
    "## Retrieve Data and Compute Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73fbc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
    "from divexplorer.FP_Divergence import FP_Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b043ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Columns of the df file that we are going to analyze \n",
    "demo_cols = ['Self-reported fluency level ', 'First Language spoken',\n",
    "       'Current language used for work/school', 'gender', 'ageRange']\n",
    "\n",
    "slot_cols = ['action', 'object', 'location']\n",
    "\n",
    "signal_cols = ['total_silence', 'total_duration', 'trimmed_duration', \n",
    "       'n_words', 'speed_rate_word', 'speed_rate_word_trimmed'] \n",
    "\n",
    "input_cols = demo_cols + signal_cols + slot_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66552fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach = \"divexplorer\" \n",
    "min_sup = 0.03\n",
    "k = 2\n",
    "\n",
    "configs = [\n",
    "    \"fsc_original\",\n",
    "    \"fsc_csi\",\n",
    "    \"fsc_cm\",\n",
    "    \"fsc_knn\",\n",
    "    \"fsc_random\", \n",
    "    \"fsc_supervised_oracle\",\n",
    "    \"fsc_metadata_oracle\",\n",
    "    \"fsc_all\"\n",
    "    ] \n",
    "    \n",
    "FP_fm_dict = {}\n",
    "fp_divergence_dict = {}\n",
    "df_dict = {}\n",
    "\n",
    "for config in configs:\n",
    "\n",
    "    print(config)\n",
    "\n",
    "    if config == \"fsc_original\" or config == \"fsc_all\":\n",
    "        input_file_divexplorer = os.path.join(\\\n",
    "            os.getcwd(), \"results\", \"fsc\", config, \"42\", \"df_test.csv\")\n",
    "    else:\n",
    "        input_file_divexplorer = os.path.join(\\\n",
    "            os.getcwd(), \"results\", \"fsc\", config, f\"k_{k}\", \"42\", \"df_test.csv\")\n",
    "    df = pd.read_csv(input_file_divexplorer, index_col=0)\n",
    "\n",
    "    ## Add SpeakerID information if it is present in the df\n",
    "    if \"speakerId\" in input_cols:\n",
    "        df['speakerId'] = df.index.map(lambda x: x.split(\"/\")[2])\n",
    "\n",
    "    ## Discretize the dataframe\n",
    "    from divergence_utils import discretize\n",
    "\n",
    "    df_discretized = discretize(\n",
    "        df[input_cols+[target_col]],\n",
    "        bins=3,\n",
    "        attributes=input_cols,\n",
    "        strategy=\"quantile\", \n",
    "        round_v = 2,\n",
    "        min_distinct=5,\n",
    "    )\n",
    "\n",
    "    ## Replace values with ranges: \"low\", \"medium\", \"high\"\n",
    "    replace_values = {}\n",
    "\n",
    "    for i in range(0,len(signal_cols)):\n",
    "\n",
    "        for v in df_discretized[signal_cols[i]].unique():\n",
    "            if \"<=\" == v[0:2]:\n",
    "                replace_values[v] = \"low\"\n",
    "            elif \">\" == v[0]:\n",
    "                replace_values[v] = \"high\"\n",
    "            elif \"(\"  == v[0] and \"]\"  == v[-1]:\n",
    "                replace_values[v] = \"medium\"\n",
    "            else:\n",
    "                raise ValueError(v)\n",
    "\n",
    "        df_discretized[signal_cols[i]].replace(replace_values, inplace=True)\n",
    "        \n",
    "    df_discretized.loc[df_discretized[\"location\"]==\"none_location\", \"location\"] = \"none\"\n",
    "    df_discretized.loc[df_discretized[\"object\"]==\"none_object\", \"object\"] = \"none\"\n",
    "\n",
    "    ## Create dict of Divergence df\n",
    "    df_dict[config] = df_discretized\n",
    "    fp_diver = FP_DivergenceExplorer(\n",
    "        df_discretized, \n",
    "        true_class_name=target_col, \n",
    "        class_map={\"P\":1, \"N\":0}\n",
    "        )\n",
    "    FP_fm = fp_diver.getFrequentPatternDivergence(\n",
    "        min_support=min_sup, \n",
    "        metrics=[target_metric]\n",
    "        )\n",
    "    FP_fm.rename(\n",
    "        columns=remapped_cols, \n",
    "        inplace=True\n",
    "        )\n",
    "    FP_fm = FP_fm[show_cols].copy()\n",
    "    FP_fm['accuracy'] = round(FP_fm['accuracy'], 5)\n",
    "    FP_fm['d_accuracy'] = round(FP_fm['d_accuracy'], 5)\n",
    "    FP_fm['t_value'] = round(FP_fm['t_value'], 2)\n",
    "    FP_fm_dict[config] = FP_fm\n",
    "    fp_divergence_dict[config] = FP_Divergence(FP_fm, target_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaecec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the accuracy of the models\n",
    "for config in configs:\n",
    "    prediction = df_dict[config]['prediction'].sum()/len(df_dict[config])\n",
    "    print(f\"Accuracy of {config}:\", round(100*prediction,3))\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7857d9ad",
   "metadata": {},
   "source": [
    "## Divergence wav2vec 2.0 base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_redundancy = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f805595c",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b6a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 base\n",
    "config = 'fsc_original'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(k).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for wav2vec 2.0 base\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdce4de",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b4407",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 base w/ random samples \n",
    "config = 'fsc_random'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(k).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for wav2vec 2.0 base w/ random samples\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c80186",
   "metadata": {},
   "source": [
    "### CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f815e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 base w/ CM samples\n",
    "config = 'fsc_cm'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(k).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for wav2vec 2.0 base rebalanced w/ CM samples\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4a441a",
   "metadata": {},
   "source": [
    "### CSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86bcd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 base w/ CSI samples\n",
    "config = 'fsc_csi'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(k).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for wav2vec 2.0 base w/ CSI samples\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da8aa79",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c05045",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 base w/ KNN \n",
    "config = 'fsc_knn'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(k).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for wav2vec 2.0 base w/ KNN \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31807a02",
   "metadata": {},
   "source": [
    "### Supervised Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a09845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 base w/ Supervised Oracle \n",
    "config = 'fsc_supervised_oracle'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(k).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for wav2vec 2.0 base w/ Supervised Oracle\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b3ae7b",
   "metadata": {},
   "source": [
    "### Metadata Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 base w/ Metadata Oracle \n",
    "config = 'fsc_metadata_oracle'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(k).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for wav2vec 2.0 base w/ Metadata Oracle  \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c3d2d8",
   "metadata": {},
   "source": [
    "### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f089cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for wav2vec 2.0 base w/ all the samples\n",
    "config = 'fsc_all'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(k).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for wav2vec 2.0 base w/ all the samples \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e7d20f",
   "metadata": {},
   "source": [
    "# ITALIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcef4184",
   "metadata": {},
   "source": [
    "## Retrieve Data and Compute Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
    "from divexplorer.FP_Divergence import FP_Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f3c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Columns of the df file that we are going to analyze \n",
    "demo_cols = ['gender', 'age', 'region', 'nationality', 'lisp', 'education']\n",
    "\n",
    "slot_cols = ['action', 'scenario']\n",
    "\n",
    "rec_set_cols = ['environment', 'device', 'field']\n",
    "\n",
    "signal_cols = ['total_silence', 'total_duration', 'trimmed_duration', \n",
    "'n_words', 'speed_rate_word', 'speed_rate_word_trimmed'] \n",
    "\n",
    "input_cols = demo_cols + slot_cols + rec_set_cols + signal_cols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7155bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach = \"divexplorer\" \n",
    "min_sup = 0.03\n",
    "k = 2\n",
    "\n",
    "configs = [\n",
    "    \"italic_original\",\n",
    "    \"italic_csi\",\n",
    "    \"italic_cm\",\n",
    "    \"italic_knn\",\n",
    "    \"italic_random\", \n",
    "    \"italic_supervised_oracle\",\n",
    "    \"italic_metadata_oracle\",\n",
    "    \"italic_all\"\n",
    "    ] \n",
    "    \n",
    "FP_fm_dict = {}\n",
    "fp_divergence_dict = {}\n",
    "df_dict = {}\n",
    "\n",
    "for config in configs:\n",
    "\n",
    "    print(config)\n",
    "\n",
    "    if config == \"italic_original\" or config == \"italic_all\":\n",
    "        input_file_divexplorer = os.path.join(\\\n",
    "            os.getcwd(), \"results\", \"italic\", config, \"42\", \"df_test.csv\")\n",
    "    else:\n",
    "        input_file_divexplorer = os.path.join(\\\n",
    "            os.getcwd(), \"results\", \"italic\", config, f\"k_{k}\", \"42\", \"df_test.csv\")\n",
    "\n",
    "    df = pd.read_csv(input_file_divexplorer, index_col=0)\n",
    "    df['action'] = df['intent'].apply(lambda x: x.split(\"_\")[0])\n",
    "    df['scenario'] = df['intent'].apply(lambda x: x.split(\"_\")[1])\n",
    "\n",
    "    ## Discretize the dataframe\n",
    "    from divergence_utils import discretize\n",
    "\n",
    "    df_discretized = discretize(\n",
    "        df[input_cols+[target_col]],\n",
    "        bins=3,\n",
    "        attributes=input_cols,\n",
    "        strategy=\"quantile\", \n",
    "        round_v = 2,\n",
    "        min_distinct=5,\n",
    "    )\n",
    "\n",
    "    ## Replace values with ranges: \"low\", \"medium\", \"high\"\n",
    "    replace_values = {}\n",
    "\n",
    "    for i in range(0,len(signal_cols)):\n",
    "\n",
    "        for v in df_discretized[signal_cols[i]].unique():\n",
    "            if \"<=\" == v[0:2]:\n",
    "                replace_values[v] = \"low\"\n",
    "            elif \">\" == v[0]:\n",
    "                replace_values[v] = \"high\"\n",
    "            elif \"(\"  == v[0] and \"]\"  == v[-1]:\n",
    "                replace_values[v] = \"medium\"\n",
    "            else:\n",
    "                raise ValueError(v)\n",
    "\n",
    "        df_discretized[signal_cols[i]].replace(replace_values, inplace=True)\n",
    "\n",
    "    ## Create dict of Divergence df\n",
    "    df_dict[config] = df_discretized\n",
    "    fp_diver = FP_DivergenceExplorer(\n",
    "        df_discretized, \n",
    "        true_class_name=target_col, \n",
    "        class_map={\"P\":1, \"N\":0}\n",
    "        )\n",
    "    FP_fm = fp_diver.getFrequentPatternDivergence(\n",
    "        min_support=min_sup, \n",
    "        metrics=[target_metric]\n",
    "        )\n",
    "    FP_fm.rename(\n",
    "        columns=remapped_cols, \n",
    "        inplace=True\n",
    "        )\n",
    "    FP_fm = FP_fm[show_cols].copy()\n",
    "    FP_fm['accuracy'] = round(FP_fm['accuracy'], 5)\n",
    "    FP_fm['d_accuracy'] = round(FP_fm['d_accuracy'], 5)\n",
    "    FP_fm['t_value'] = round(FP_fm['t_value'], 2)\n",
    "    FP_fm_dict[config] = FP_fm\n",
    "    fp_divergence_dict[config] = FP_Divergence(FP_fm, target_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480e5725",
   "metadata": {},
   "source": [
    "## Divergence XLSR300m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1411bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_redundancy = None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98110593",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR300m\n",
    "config = 'italic_original'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for XLSR300m\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4372aa3d",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1015110",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR300m w/ random samples\n",
    "config = 'italic_random'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for XLSR300m w/ random samples \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbff606",
   "metadata": {},
   "source": [
    "### CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR300m w/ CM samples\n",
    "config = 'italic_cm'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for XLSR300m w/ CM samples\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb82e5",
   "metadata": {},
   "source": [
    "### CSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126583c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR300m w/ CSI samples\n",
    "config = 'italic_csi'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for XLSR300m w/ CSI samples\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aa8c74",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e7d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR300m w/ KNN samples\n",
    "config = 'italic_knn'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for XLSR300m w/ KNN samples\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd008708",
   "metadata": {},
   "source": [
    "### Supervised Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8655fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR300m w/ Supervised Oracle\n",
    "config = 'italic_supervised_oracle'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for XLSR300m w/ Supervised Oracle\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0437194d",
   "metadata": {},
   "source": [
    "### Metadata Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c796e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR300m w/ Metadata Oracle\n",
    "config = 'italic_metadata_oracle'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for XLSR300m w/ Metadata Oracle\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b0486",
   "metadata": {},
   "source": [
    "### All "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d6b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for XLSR300m w/ all the samples\n",
    "config = 'italic_all'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"#errors\"] = pr_bot[\"#errors\"].astype(int)\n",
    "pr_bot[\"#corrects\"] = pr_bot[\"#corrects\"].astype(int)\n",
    "pr_bot[\"accuracy\"] = (pr_bot[\"accuracy\"]*100).round(3)\n",
    "pr_bot[\"d_accuracy\"] = (pr_bot[\"d_accuracy\"]*100).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"accuracy\", \"d_accuracy\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for wav2vec 2.0 base w/ all the samples\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1]\n",
    "pr = FPdiv[FPdiv['d_accuracy'] < 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_accuracy'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['accuracy'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da8941d",
   "metadata": {},
   "source": [
    "# LibriSpeech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ee5a9",
   "metadata": {},
   "source": [
    "## Retrieve Data and Compute Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f882fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
    "from divexplorer.FP_Divergence import FP_Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a53868",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Target for DivExplorer: 'WER'\n",
    "target_col = 'WER' \n",
    "target_metric = 'd_outcome'\n",
    "target_div = f'd_{target_col}'\n",
    "t_value_col = 't_value_outcome'\n",
    "printable_columns = ['support', 'itemsets','WER', 'd_WER', 't_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57add94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Columns for visualization\n",
    "remapped_cols = { \"outcome\": target_col, \"d_outcome\": target_div, t_value_col: 't_value'}\n",
    "show_cols = ['support', 'itemsets', target_col, target_div, 'support_count', 'length', 't_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee034e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Columns of the df file that we are going to analyze \n",
    "demo_cols = ['gender']\n",
    "\n",
    "signal_cols = ['total_silence', 'total_duration', 'n_pauses', 'n_words', 'speed_rate_word'] \n",
    "\n",
    "input_cols = demo_cols + signal_cols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach = \"divexplorer\" \n",
    "min_sup = 0.03\n",
    "k = 2\n",
    "\n",
    "configs = [\n",
    "    \"librispeech_original\",\n",
    "    \"librispeech_csi\",\n",
    "    \"librispeech_cm\",\n",
    "    \"librispeech_knn\",\n",
    "    \"librispeech_random\", \n",
    "    \"librispeech_supervised_oracle\",\n",
    "    \"librispeech_metadata_oracle\",\n",
    "    \"librispeech_all\"\n",
    "    ] \n",
    "    \n",
    "FP_fm_dict = {}\n",
    "fp_divergence_dict = {}\n",
    "df_dict = {}\n",
    "\n",
    "for config in configs:\n",
    "\n",
    "    print(config)\n",
    "\n",
    "    if config == \"librispeech_original\" or config == \"librispeech_all\":\n",
    "        input_file_divexplorer = os.path.join(\\\n",
    "            os.getcwd(), \"results\", \"librispeech\", config, \"42\", \"df_test.csv\")\n",
    "    else:\n",
    "        input_file_divexplorer = os.path.join(\\\n",
    "            os.getcwd(), \"results\", \"librispeech\", config, f\"k_{k}\", \"42\", \"df_test.csv\")\n",
    "\n",
    "    df = pd.read_csv(input_file_divexplorer, index_col=0)\n",
    "\n",
    "    ## Discretize the dataframe\n",
    "    from divergence_utils import discretize\n",
    "\n",
    "    df_discretized = discretize(\n",
    "        df[input_cols+[target_col]],\n",
    "        bins=3,\n",
    "        attributes=input_cols,\n",
    "        strategy=\"quantile\", \n",
    "        round_v = 2,\n",
    "        min_distinct=5,\n",
    "    )\n",
    "\n",
    "    ## Replace values with ranges: \"low\", \"medium\", \"high\"\n",
    "    replace_values = {}\n",
    "\n",
    "    for i in range(0,len(signal_cols)):\n",
    "\n",
    "        for v in df_discretized[signal_cols[i]].unique():\n",
    "            if \"<=\" == v[0:2]:\n",
    "                replace_values[v] = \"low\"\n",
    "            elif \">\" == v[0]:\n",
    "                replace_values[v] = \"high\"\n",
    "            elif \"(\"  == v[0] and \"]\"  == v[-1]:\n",
    "                replace_values[v] = \"medium\"\n",
    "            else:\n",
    "                raise ValueError(v)\n",
    "\n",
    "        df_discretized[signal_cols[i]].replace(replace_values, inplace=True)\n",
    "\n",
    "    ## Create dict of Divergence df\n",
    "    df_dict[config] = df_discretized\n",
    "\n",
    "    fp_diver = FP_DivergenceExplorer(\n",
    "        df_discretized, \n",
    "        target_name=target_col\n",
    "        )\n",
    "    FP_fm = fp_diver.getFrequentPatternDivergence(\n",
    "        min_support=min_sup, \n",
    "        metrics=[target_metric]\n",
    "        )\n",
    "        \n",
    "    FP_fm.rename(\n",
    "        columns=remapped_cols, \n",
    "        inplace=True\n",
    "        )\n",
    "    FP_fm = FP_fm[show_cols].copy()\n",
    "    FP_fm['WER'] = round(FP_fm['WER'], 5)\n",
    "    FP_fm['d_WER'] = round(FP_fm['d_WER'], 5)\n",
    "    FP_fm['t_value'] = round(FP_fm['t_value'], 2)\n",
    "    FP_fm_dict[config] = FP_fm\n",
    "    fp_divergence_dict[config] = FP_Divergence(FP_fm, target_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute WER for each config\n",
    "from jiwer import wer\n",
    "\n",
    "wers = {}\n",
    "\n",
    "for config in configs:\n",
    "\n",
    "    print(config)\n",
    "    \n",
    "    if config == \"librispeech_original\" or config == \"librispeech_all\":\n",
    "        input_file_divexplorer = os.path.join(\\\n",
    "            os.getcwd(), \"results\", \"librispeech\", config, \"42\", \"df_test.csv\")\n",
    "    else:\n",
    "        input_file_divexplorer = os.path.join(\\\n",
    "            os.getcwd(), \"results\", \"librispeech\", config, f\"k_{k}\", \"42\", \"df_test.csv\")\n",
    "\n",
    "    df = pd.read_csv(input_file_divexplorer, index_col=0)\n",
    "\n",
    "    ground_truth = list(df['text'])\n",
    "    hypothesis =list(df['transcription'])\n",
    "    WER = wer(ground_truth, hypothesis)*100\n",
    "    wers[config] = WER\n",
    "\n",
    "    print(f\"WER of {config}:\", round(WER, 3))\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b4063",
   "metadata": {},
   "source": [
    "## Divergence Whisper base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef5aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_redundancy = None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d257cd",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44dc86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for whisper base\n",
    "config = 'librispeech_original'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"WER\"] = (pr_bot[\"WER\"]*100).round(3)\n",
    "pr_bot[\"d_WER\"] = ((pr_bot[\"WER\"] - wers[config])).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"WER\", \"d_WER\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for whisper base\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "pr = FPdiv[FPdiv['d_WER'] > 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_WER'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['WER'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584edf47",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18483fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for whisper base w/ random samples\n",
    "config = 'librispeech_random'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"WER\"] = (pr_bot[\"WER\"]*100).round(3)\n",
    "pr_bot[\"d_WER\"] = ((pr_bot[\"WER\"] - wers[config])).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"WER\", \"d_WER\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for whisper base w/ random samples\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "pr = FPdiv[FPdiv['d_WER'] > 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_WER'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['WER'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fef0cfe",
   "metadata": {},
   "source": [
    "### CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20983ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for whisper base w/ CM samples\n",
    "config = 'librispeech_cm'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"WER\"] = (pr_bot[\"WER\"]*100).round(3)\n",
    "pr_bot[\"d_WER\"] = ((pr_bot[\"WER\"] - wers[config])).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"WER\", \"d_WER\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for whisper base w/ CM samples\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "pr = FPdiv[FPdiv['d_WER'] > 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_WER'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['WER'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a502353",
   "metadata": {},
   "source": [
    "### CSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23df578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for whisper base w/ CSI samples\n",
    "config = 'librispeech_csi'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"WER\"] = (pr_bot[\"WER\"]*100).round(3)\n",
    "pr_bot[\"d_WER\"] = ((pr_bot[\"WER\"] - wers[config])).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"WER\", \"d_WER\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for whisper base w/ CSI samples\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "pr = FPdiv[FPdiv['d_WER'] > 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_WER'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['WER'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7158c58",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a67f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for whisper base w/ KNN samples\n",
    "config = 'librispeech_knn'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"WER\"] = (pr_bot[\"WER\"]*100).round(3)\n",
    "pr_bot[\"d_WER\"] = ((pr_bot[\"WER\"] - wers[config])).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"WER\", \"d_WER\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for whisper base w/ KNN samples\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "pr = FPdiv[FPdiv['d_WER'] > 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_WER'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['WER'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54590fec",
   "metadata": {},
   "source": [
    "### Supervised Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269509c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for whisper base w/ Supervised Oracle\n",
    "config = 'librispeech_supervised_oracle'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"WER\"] = (pr_bot[\"WER\"]*100).round(3)\n",
    "pr_bot[\"d_WER\"] = ((pr_bot[\"WER\"] - wers[config])).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"WER\", \"d_WER\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for whisper base w/ Supervised Oracle\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "pr = FPdiv[FPdiv['d_WER'] > 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_WER'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['WER'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e703af5b",
   "metadata": {},
   "source": [
    "### Metadata Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1282f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for whisper base w/ Metadata Oracle\n",
    "config = 'librispeech_metadata_oracle'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"WER\"] = (pr_bot[\"WER\"]*100).round(3)\n",
    "pr_bot[\"d_WER\"] = ((pr_bot[\"WER\"] - wers[config])).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"WER\", \"d_WER\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for whisper base w/ Metadata Oracle\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "pr = FPdiv[FPdiv['d_WER'] > 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_WER'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['WER'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b740eec",
   "metadata": {},
   "source": [
    "### All "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f62cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the divergence for whisper base w/ all the samples\n",
    "config = 'librispeech_all'\n",
    "fp_divergence_i = fp_divergence_dict[config]\n",
    "\n",
    "n = 2\n",
    "\n",
    "## Retrieve Most Negatively Divergent Itemsets \n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "pr_bot = FPdiv.head(n).copy()\n",
    "pr_bot[\"support\"] = pr_bot[\"support\"].round(2)\n",
    "pr_bot[\"WER\"] = (pr_bot[\"WER\"]*100).round(3)\n",
    "pr_bot[\"d_WER\"] = ((pr_bot[\"WER\"] - wers[config])).round(3)\n",
    "## Choose columns for better visualization \n",
    "pr_l_bot = pr_bot[[ \"itemsets\", \"support\", \"WER\", \"d_WER\", \"t_value\"]].copy()\n",
    "pr_l_bot['itemsets'] = pr_l_bot['itemsets'].apply(lambda x: sortItemset(x, abbreviations))\n",
    "display(pr_l_bot)\n",
    "\n",
    "## Compute the mean negative divergence for whisper base w/ all the samples\n",
    "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)\n",
    "pr = FPdiv[FPdiv['d_WER'] > 0].head(k).copy()\n",
    "print(f\"Mean negative divergence top {k}:\", round(100*pr['d_WER'].mean(), 3))\n",
    "print(f\"Mean negative accuracy top {k}:\",   round(100*pr['WER'].mean(), 3))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DivExplorer_FSC_IC.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('speech': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "313.76837158203125px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "50f798c039f92e39594af06ec0119751541d975fa6ec3b2f5528645cd2e370ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
