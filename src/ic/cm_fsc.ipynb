{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cJVqXw3dRSX-"
      },
      "source": [
        "# Configuring the Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTOyqWt3RXfU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import librosa\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import divexplorer \n",
        "import pandas as pd\n",
        "pd.set_option('max_colwidth', None)\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from utils_analysis import filter_itemset_df_by_attributes, slice_by_itemset\n",
        "\n",
        "from divexplorer.FP_DivergenceExplorer import FP_DivergenceExplorer\n",
        "from divexplorer.FP_Divergence import FP_Divergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTbn0utIRbgS"
      },
      "outputs": [],
      "source": [
        "## Set device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "R2gPZZs-SaDr"
      },
      "source": [
        "# FSC Dataset - Inference and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def map_to_array(example, audio_col = 'path'):\n",
        "    speech, _ = librosa.load(example[audio_col], sr=16000, mono=True)\n",
        "    example[\"speech\"] = speech\n",
        "    return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = feature_extractor(\n",
        "      examples,\n",
        "      sampling_rate=feature_extractor.sampling_rate, \n",
        "      padding=True, \n",
        "      return_tensors=\"pt\")\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HF = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Load model\n",
        "if HF == True:\n",
        "    print(\"Loading model from HF\")\n",
        "    model_w2v2 = Wav2Vec2ForSequenceClassification.from_pretrained(\"superb/wav2vec2-base-superb-ic\").to(device)\n",
        "    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"superb/wav2vec2-base-superb-ic\")\n",
        "else: \n",
        "    print(\"Loading model from local directory\")\n",
        "    model_w2v2 = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
        "        \"fsc_original\", \n",
        "        output_hidden_states=True,\n",
        "        local_files_only=True\n",
        "        ).to(device)\n",
        "    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"superb/wav2vec2-base-superb-ic\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCSRYY5nSemQ"
      },
      "outputs": [],
      "source": [
        "## Load and preprocess dataset\n",
        "df = pd.read_csv('data/fsc/train_data_80.csv')\n",
        "\n",
        "dataset = Dataset.from_pandas(df)\n",
        "dataset = dataset.map(lambda x: map_to_array(x, audio_col='path'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmQkoBnuSkMM"
      },
      "outputs": [],
      "source": [
        "## Inference\n",
        "hidden_states_concatenation = []\n",
        "logits_concatenation = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(0, len(dataset))):\n",
        "        inputs = preprocess_function(dataset[i][\"speech\"]).to(device)\n",
        "        outputs = model_w2v2(**inputs)\n",
        "        hidden_states_concatenation.append(outputs.hidden_states[-1])\n",
        "        logits_concatenation.append(outputs.logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Save hidden states and logits\n",
        "if HF == True:\n",
        "    torch.save(hidden_states_concatenation, 'pretrained/fsc/hidden_states_train_hf.pt')\n",
        "    torch.save(logits_concatenation, 'pretrained/fsc/logits_train_hf.pt')\n",
        "else:\n",
        "    torch.save(hidden_states_concatenation, 'pretrained/fsc/hidden_states_train.pt')\n",
        "    torch.save(logits_concatenation, 'pretrained/fsc/logits_train.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Load hidden states and logits\n",
        "if HF == True:\n",
        "    hidden_states_concatenation = torch.load('pretrained/fsc/hidden_states_train_hf.pt')\n",
        "    logits_concatenation = torch.load('pretrained/fsc/logits_train_hf.pt')\n",
        "else:\n",
        "    hidden_states_concatenation = torch.load('pretrained/fsc/hidden_states_train.pt')\n",
        "    logits_concatenation = torch.load('pretrained/fsc/logits_train.pt')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "P_SSWxldSmc-"
      },
      "source": [
        "### Intent Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjUcqGR-SpVq",
        "outputId": "50e6bdd6-cd77-48e4-8883-e57750d46f93"
      },
      "outputs": [],
      "source": [
        "if HF == True:\n",
        "\n",
        "    ## Action\n",
        "    action_ids = []\n",
        "    for i in range(len(logits_concatenation)):\n",
        "        logits = logits_concatenation[i].detach().cpu()\n",
        "        action_ids.append(torch.argmax(logits[:, :6], dim=-1).item())\n",
        "    action_labels = [model_w2v2.config.id2label[_id] for _id in action_ids]\n",
        "    action_gt = list(df['action'].values)\n",
        "    print(\"Action accuracy: \", round(accuracy_score(action_gt, action_labels)*100, 2), \"%\")\n",
        "\n",
        "    ## Object\n",
        "    object_ids = []\n",
        "    for i in range(len(logits_concatenation)):\n",
        "        logits = logits_concatenation[i].detach().cpu()\n",
        "        object_ids.append(torch.argmax(logits[:, 6:20], dim=-1).item())\n",
        "    object_labels = [model_w2v2.config.id2label[_id + 6] for _id in object_ids]\n",
        "    object_gt = list(df['object'].values)\n",
        "    object_gt = [f'{x}_object' if x=='none' else x for x in object_gt]\n",
        "    print(\"Obejct accuracy: \", round(accuracy_score(object_gt, object_labels)*100, 2), \"%\")\n",
        "\n",
        "    ## Location\n",
        "    location_ids = []\n",
        "    for i in range(len(logits_concatenation)):\n",
        "        logits = logits_concatenation[i].detach().cpu()\n",
        "        location_ids.append(torch.argmax(logits[:, 20:24], dim=-1).item())\n",
        "    location_labels = [model_w2v2.config.id2label[_id + 20] for _id in location_ids]\n",
        "    location_gt = list(df['location'].values)\n",
        "    location_gt = [f'{x}_location' if x=='none' else x for x in location_gt]\n",
        "    print(\"Location accuracy: \", round(accuracy_score(location_gt, location_labels)*100, 2), \"%\")\n",
        "\n",
        "    ## Predictions\n",
        "    intents_predicted = [ action_labels[i]  + \" \" + object_labels[i] + \" \" + location_labels[i] for i in range(0, len(df))]\n",
        "    intents_gt = [ action_gt[i]  + \" \" + object_gt[i] + \" \" + location_gt[i] for i in range(0, len(df))]\n",
        "    is_correct = (np.array(intents_predicted) == np.array(intents_gt)).astype(int)\n",
        "    df['prediction'] = is_correct\n",
        "    print(\"Accuracy: \", round(np.mean(is_correct)*100,2), \"%\")\n",
        "\n",
        "    ## Save action, object and location predictions \n",
        "    df['predicted_action'] = [l[:, :6].detach().cpu().numpy().squeeze() for l in logits_concatenation]\n",
        "    df['predicted_object'] = [l[:, 6:20].detach().cpu().numpy().squeeze() for l in logits_concatenation]\n",
        "    df['predicted_location'] = [l[:, 20:24].detach().cpu().numpy().squeeze() for l in logits_concatenation]\n",
        "\n",
        "else:\n",
        "\n",
        "    ## Intents\n",
        "    intents_predicted = []\n",
        "    for i in range(len(logits_concatenation)):\n",
        "        logits = logits_concatenation[i].detach().cpu()\n",
        "        intent = torch.argmax(logits, dim=-1).item()\n",
        "        intents_predicted.append(model_w2v2.config.id2label[intent])\n",
        "    action_gt = list(df['action'].values)\n",
        "    object_gt = list(df['object'].values)\n",
        "    location_gt = list(df['location'].values)\n",
        "    intents_gt = [ action_gt[i]  + \"\" + object_gt[i] + \"\" + location_gt[i] for i in range(0, len(df))]\n",
        "\n",
        "    ## Predictions\n",
        "    is_correct = (np.array(intents_predicted) == np.array(intents_gt)).astype(int)\n",
        "    df['prediction'] = is_correct\n",
        "    print(\"Accuracy: \", round(np.mean(is_correct)*100,2), \"%\")\n",
        "\n",
        "    ## Save predictions\n",
        "    df['predicted_intent'] = [l.detach().cpu().numpy().squeeze() for l in logits_concatenation]\n",
        "\n",
        "## Save hidden states\n",
        "df['hidden_states'] = [hs.detach().cpu().numpy().squeeze() for hs in hidden_states_concatenation]\n",
        "df['hidden_states'] = df['hidden_states'].apply(lambda x: x.astype(float))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if HF == True:\n",
        "    output_folder = os.path.join(f'data/fsc/fsc_train_80_hf.csv')\n",
        "else:\n",
        "    output_folder = os.path.join(f'data/fsc/fsc_train_80.csv')\n",
        "df.to_csv(output_folder, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Load and preprocess dataset\n",
        "df_valid = pd.read_csv('data/fsc/valid_data.csv')\n",
        "\n",
        "dataset_valid = Dataset.from_pandas(df_valid) \n",
        "dataset_valid = dataset_valid.map(lambda x: map_to_array(x, audio_col='path'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Inference\n",
        "hidden_states_concatenation_valid = []\n",
        "logits_concatenation_valid = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(0, len(dataset_valid))):\n",
        "        inputs = preprocess_function(dataset_valid[i][\"speech\"]).to(device)\n",
        "        outputs = model_w2v2(**inputs)\n",
        "        hidden_states_concatenation_valid.append(outputs.hidden_states[-1])\n",
        "        logits_concatenation_valid.append(outputs.logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Save hidden states and logits\n",
        "if HF == True:\n",
        "    torch.save(hidden_states_concatenation_valid, 'pretrained/fsc/hidden_states_valid_hf.pt')\n",
        "    torch.save(logits_concatenation_valid, 'pretrained/fsc/logits_valid_hf.pt')\n",
        "else:\n",
        "    torch.save(hidden_states_concatenation_valid, 'pretrained/fsc/hidden_states_valid.pt')\n",
        "    torch.save(logits_concatenation_valid, 'pretrained/fsc/logits_valid.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Load hidden states and logits\n",
        "if HF == True:\n",
        "    hidden_states_concatenation_valid = torch.load('pretrained/fsc/hidden_states_valid_hf.pt')\n",
        "    logits_concatenation_valid = torch.load('pretrained/fsc/logits_valid_hf.pt')\n",
        "else:\n",
        "    hidden_states_concatenation_valid = torch.load('pretrained/fsc/hidden_states_valid.pt')\n",
        "    logits_concatenation_valid = torch.load('pretrained/fsc/logits_valid.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Intent Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if HF == True:\n",
        "\n",
        "    ## Action\n",
        "    action_ids = []\n",
        "    for i in range(len(logits_concatenation_valid)):\n",
        "        logits = logits_concatenation_valid[i].detach().cpu()\n",
        "        action_ids.append(torch.argmax(logits[:, :6], dim=-1).item())\n",
        "    action_labels = [model.config.id2label[_id] for _id in action_ids]\n",
        "    action_gt = list(df_valid['action'].values)\n",
        "    print(\"Action accuracy: \", round(accuracy_score(action_gt, action_labels)*100, 2), \"%\")\n",
        "\n",
        "    ## Object\n",
        "    object_ids = []\n",
        "    for i in range(len(logits_concatenation_valid)):\n",
        "        logits = logits_concatenation_valid[i].detach().cpu()\n",
        "        object_ids.append(torch.argmax(logits[:, 6:20], dim=-1).item())\n",
        "    object_labels = [model.config.id2label[_id + 6] for _id in object_ids]\n",
        "    object_gt = list(df_valid['object'].values)\n",
        "    object_gt = [f'{x}_object' if x=='none' else x for x in object_gt]\n",
        "    print(\"Obejct accuracy: \", round(accuracy_score(object_gt, object_labels)*100, 2), \"%\")\n",
        "\n",
        "    ## Location\n",
        "    location_ids = []\n",
        "    for i in range(len(logits_concatenation_valid)):\n",
        "        logits = logits_concatenation_valid[i].detach().cpu()\n",
        "        location_ids.append(torch.argmax(logits[:, 20:24], dim=-1).item())\n",
        "    location_labels = [model.config.id2label[_id + 20] for _id in location_ids]\n",
        "    location_gt = list(df_valid['location'].values)\n",
        "    location_gt = [f'{x}_location' if x=='none' else x for x in location_gt]\n",
        "    print(\"Location accuracy: \", round(accuracy_score(location_gt, location_labels)*100, 2), \"%\")\n",
        "\n",
        "    ## Predictions\n",
        "    intents_predicted = [ action_labels[i]  + \" \" + object_labels[i] + \" \" + location_labels[i] for i in range(0, len(df_valid))]\n",
        "    intents_gt = [ action_gt[i]  + \" \" + object_gt[i] + \" \" + location_gt[i] for i in range(0, len(df_valid))]\n",
        "    is_correct = (np.array(intents_predicted) == np.array(intents_gt)).astype(int)\n",
        "    df_valid['prediction'] = is_correct\n",
        "    print(\"Accuracy: \", round(np.mean(is_correct)*100,2), \"%\")\n",
        "\n",
        "    ## Save action, object and location predictions\n",
        "    df_valid['predicted_action'] = [l[:, :6].detach().cpu().numpy().squeeze() for l in logits_concatenation_valid]\n",
        "    df_valid['predicted_object'] = [l[:, 6:20].detach().cpu().numpy().squeeze() for l in logits_concatenation_valid]\n",
        "    df_valid['predicted_location'] = [l[:, 20:24].detach().cpu().numpy().squeeze() for l in logits_concatenation_valid]\n",
        "\n",
        "else:\n",
        "\n",
        "    ## Intents\n",
        "    intents_predicted = []\n",
        "    for i in range(len(logits_concatenation_valid)):\n",
        "        logits = logits_concatenation_valid[i].detach().cpu()\n",
        "        intent = torch.argmax(logits, dim=-1).item()\n",
        "        intents_predicted.append(model_w2v2.config.id2label[intent])\n",
        "    action_gt = list(df_valid['action'].values)\n",
        "    object_gt = list(df_valid['object'].values)\n",
        "    location_gt = list(df_valid['location'].values)\n",
        "    intents_gt = [ action_gt[i]  + \"\" + object_gt[i] + \"\" + location_gt[i] for i in range(0, len(df_valid))]\n",
        "\n",
        "    ## Predictions\n",
        "    is_correct = (np.array(intents_predicted) == np.array(intents_gt)).astype(int)\n",
        "    df_valid['prediction'] = is_correct\n",
        "    print(\"Accuracy: \", round(np.mean(is_correct)*100,2), \"%\")\n",
        "\n",
        "    ## Save predictions\n",
        "    df_valid['predicted_intent'] = [l.detach().cpu().numpy().squeeze() for l in logits_concatenation_valid]\n",
        "\n",
        "## Save hidden states\n",
        "df_valid['hidden_states'] = [hs.detach().cpu().numpy().squeeze() for hs in hidden_states_concatenation_valid]\n",
        "df_valid['hidden_states'] = df_valid['hidden_states'].apply(lambda x: x.astype(float))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if HF == True:\n",
        "    output_folder = os.path.join(f'data/fsc/fsc_valid_hf.csv')\n",
        "else:\n",
        "    output_folder = os.path.join(f'data/fsc/fsc_valid.csv')\n",
        "df_valid.to_csv(output_folder, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading Pretrained Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HF = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Load model\n",
        "if HF == True:\n",
        "    print(\"Loading model from HF\")\n",
        "    model_w2v2 = Wav2Vec2ForSequenceClassification.from_pretrained(\"superb/wav2vec2-base-superb-ic\").to(device)\n",
        "    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"superb/wav2vec2-base-superb-ic\")\n",
        "else: \n",
        "    print(\"Loading model from local directory\")\n",
        "    model_w2v2 = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
        "        \"fsc_original/9/checkpoint-2000\", \n",
        "        output_hidden_states=True,\n",
        "        local_files_only=True\n",
        "        ).to(device)\n",
        "    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"superb/wav2vec2-base-superb-ic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Load and preprocess dataset\n",
        "df = pd.read_csv('data/fsc/train_data_80.csv')\n",
        "\n",
        "if HF == True:\n",
        "\n",
        "    ## Load hidden states and logits\n",
        "    hidden_states_concatenation_train = torch.load('pretrained/fsc/hidden_states_train_hf.pt')\n",
        "    logits_concatenation_train = torch.load('pretrained/fsc/logits_train_hf.pt')\n",
        "\n",
        "    ## Actions\n",
        "    action_ids = []\n",
        "    for i in range(len(logits_concatenation_train)):\n",
        "        logits = logits_concatenation_train[i].detach().cpu()\n",
        "        action_ids.append(torch.argmax(logits[:, :6], dim=-1).item())\n",
        "    action_labels = [model.config.id2label[_id] for _id in action_ids]\n",
        "    action_gt = list(df['action'].values)\n",
        "\n",
        "    ## Objects\n",
        "    object_ids = []\n",
        "    for i in range(len(logits_concatenation_train)):\n",
        "        logits = logits_concatenation_train[i].detach().cpu()\n",
        "        object_ids.append(torch.argmax(logits[:, 6:20], dim=-1).item())\n",
        "    object_labels = [model.config.id2label[_id + 6] for _id in object_ids]\n",
        "    object_gt = list(df['object'].values)\n",
        "    object_gt = [f'{x}_object' if x=='none' else x for x in object_gt]\n",
        "\n",
        "    ## Locations\n",
        "    location_ids = []\n",
        "    for i in range(len(logits_concatenation_train)):\n",
        "        logits = logits_concatenation_train[i].detach().cpu()\n",
        "        location_ids.append(torch.argmax(logits[:, 20:24], dim=-1).item())\n",
        "    location_labels = [model.config.id2label[_id + 20] for _id in location_ids]\n",
        "    location_gt = list(df['location'].values)\n",
        "    location_gt = [f'{x}_location' if x=='none' else x for x in location_gt]\n",
        "\n",
        "    ## Predictions\n",
        "    intents_predicted = [ action_labels[i]  + \" \" + object_labels[i] + \" \" + location_labels[i] for i in range(0, len(df))]\n",
        "    intents_gt = [ action_gt[i]  + \" \" + object_gt[i] + \" \" + location_gt[i] for i in range(0, len(df))]\n",
        "    is_correct = (np.array(intents_predicted) == np.array(intents_gt)).astype(int)\n",
        "    df['prediction'] = is_correct\n",
        "\n",
        "    ## Action, object and location predictions \n",
        "    df['predicted_action'] = [l[:, :6].detach().cpu().numpy().squeeze() for l in logits_concatenation_train]\n",
        "    df['predicted_object'] = [l[:, 6:20].detach().cpu().numpy().squeeze() for l in logits_concatenation_train]\n",
        "    df['predicted_location'] = [l[:, 20:24].detach().cpu().numpy().squeeze() for l in logits_concatenation_train]\n",
        "\n",
        "    ## Hidden states\n",
        "    df['hidden_states'] = [hs.detach().cpu().numpy().squeeze() for hs in hidden_states_concatenation_train]\n",
        "    df['hidden_states'] = df['hidden_states'].apply(lambda x: x.astype(float))\n",
        "    \n",
        "else:\n",
        "\n",
        "    print(\"Starting from local model\")\n",
        "    ## Load hidden states and logits\n",
        "    hidden_states_concatenation_train = torch.load('pretrained/fsc/hidden_states_train.pt')\n",
        "    logits_concatenation_train = torch.load('pretrained/fsc/logits_train.pt')\n",
        "\n",
        "    ## Intents\n",
        "    intents_predicted = []\n",
        "    for i in range(len(logits_concatenation_train)):\n",
        "        logits = logits_concatenation_train[i].detach().cpu()\n",
        "        intent = torch.argmax(logits, dim=-1).item()\n",
        "        intents_predicted.append(model_w2v2.config.id2label[intent])\n",
        "    action_gt = list(df['action'].values)\n",
        "    object_gt = list(df['object'].values)\n",
        "    location_gt = list(df['location'].values)\n",
        "    intents_gt = [ action_gt[i]  + \"\" + object_gt[i] + \"\" + location_gt[i] for i in range(0, len(df))]\n",
        "\n",
        "    ## Predictions\n",
        "    is_correct = (np.array(intents_predicted) == np.array(intents_gt)).astype(int)\n",
        "    df['prediction'] = is_correct\n",
        "    print(\"Accuracy: \", round(np.mean(is_correct)*100,2), \"%\")\n",
        "\n",
        "    ## Intent predictions\n",
        "    df['predicted_intent'] = [l.detach().cpu().numpy().squeeze() for l in logits_concatenation_train]\n",
        "\n",
        "    ## Hidden states\n",
        "    df['hidden_states'] = [hs.detach().cpu().numpy().squeeze() for hs in hidden_states_concatenation_train]\n",
        "    df['hidden_states'] = df['hidden_states'].apply(lambda x: x.astype(float))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Load and preprocess dataset\n",
        "df_valid = pd.read_csv('data/fsc/valid_data.csv')\n",
        "\n",
        "if HF == True:\n",
        "    ## Load hidden states and logits\n",
        "    hidden_states_concatenation_valid = torch.load('pretrained/fsc/hidden_states_valid_hf.pt')\n",
        "    logits_concatenation_valid = torch.load('pretrained/fsc/logits_valid_hf.pt')\n",
        "\n",
        "    ## Actions\n",
        "    action_ids = []\n",
        "    for i in range(len(logits_concatenation_valid)):\n",
        "        logits = logits_concatenation_valid[i].detach().cpu()\n",
        "        action_ids.append(torch.argmax(logits[:, :6], dim=-1).item())\n",
        "    action_labels = [model.config.id2label[_id] for _id in action_ids]\n",
        "    action_gt = list(df_valid['action'].values)\n",
        "\n",
        "    ## Objects\n",
        "    object_ids = []\n",
        "    for i in range(len(logits_concatenation_valid)):\n",
        "        logits = logits_concatenation_valid[i].detach().cpu()\n",
        "        object_ids.append(torch.argmax(logits[:, 6:20], dim=-1).item())\n",
        "    object_labels = [model.config.id2label[_id + 6] for _id in object_ids]\n",
        "    object_gt = list(df_valid['object'].values)\n",
        "    object_gt = [f'{x}_object' if x=='none' else x for x in object_gt]\n",
        "\n",
        "    ## Locations\n",
        "    location_ids = []\n",
        "    for i in range(len(logits_concatenation_valid)):\n",
        "        logits = logits_concatenation_valid[i].detach().cpu()\n",
        "        location_ids.append(torch.argmax(logits[:, 20:24], dim=-1).item())\n",
        "    location_labels = [model.config.id2label[_id + 20] for _id in location_ids]\n",
        "    location_gt = list(df_valid['location'].values)\n",
        "    location_gt = [f'{x}_location' if x=='none' else x for x in location_gt]\n",
        "\n",
        "    ## Predictions\n",
        "    intents_predicted = [ action_labels[i]  + \" \" + object_labels[i] + \" \" + location_labels[i] for i in range(0, len(df_valid))]\n",
        "    intents_gt = [ action_gt[i]  + \" \" + object_gt[i] + \" \" + location_gt[i] for i in range(0, len(df_valid))]\n",
        "    is_correct = (np.array(intents_predicted) == np.array(intents_gt)).astype(int)\n",
        "    df_valid['prediction'] = is_correct\n",
        "\n",
        "    ## Hidden states\n",
        "    df_valid['hidden_states'] = [hs.detach().cpu().numpy().squeeze() for hs in hidden_states_concatenation_valid]\n",
        "    df_valid['hidden_states'] = df_valid['hidden_states'].apply(lambda x: x.astype(float))\n",
        "\n",
        "    ## Action, object and location predictions \n",
        "    df_valid['predicted_action'] = [l[:, :6].detach().cpu().numpy().squeeze() for l in logits_concatenation_valid]\n",
        "    df_valid['predicted_object'] = [l[:, 6:20].detach().cpu().numpy().squeeze() for l in logits_concatenation_valid]\n",
        "    df_valid['predicted_location'] = [l[:, 20:24].detach().cpu().numpy().squeeze() for l in logits_concatenation_valid]\n",
        "\n",
        "else:\n",
        "\n",
        "    print(\"Starting from local model\")\n",
        "    ## Load hidden states and logits\n",
        "    hidden_states_concatenation_valid = torch.load('pretrained/fsc/hidden_states_valid.pt')\n",
        "    logits_concatenation_valid = torch.load('pretrained/fsc/logits_valid.pt')\n",
        "\n",
        "    ## Intents\n",
        "    intents_predicted = []\n",
        "    for i in range(len(logits_concatenation_valid)):\n",
        "        logits = logits_concatenation_valid[i].detach().cpu()\n",
        "        intent = torch.argmax(logits, dim=-1).item()\n",
        "        intents_predicted.append(model_w2v2.config.id2label[intent])\n",
        "    action_gt = list(df_valid['action'].values)\n",
        "    object_gt = list(df_valid['object'].values)\n",
        "    location_gt = list(df_valid['location'].values)\n",
        "    intents_gt = [ action_gt[i]  + \"\" + object_gt[i] + \"\" + location_gt[i] for i in range(0, len(df_valid))]\n",
        "\n",
        "    ## Predictions\n",
        "    is_correct = (np.array(intents_predicted) == np.array(intents_gt)).astype(int)\n",
        "    df_valid['prediction'] = is_correct\n",
        "    print(\"Accuracy: \", round(np.mean(is_correct)*100,2), \"%\")\n",
        "\n",
        "    ## Intent predictions\n",
        "    df_valid['predicted_intent'] = [l.detach().cpu().numpy().squeeze() for l in logits_concatenation_valid]\n",
        "\n",
        "    ## Hidden states\n",
        "    df_valid['hidden_states'] = [hs.detach().cpu().numpy().squeeze() for hs in hidden_states_concatenation_valid]\n",
        "    df_valid['hidden_states'] = df_valid['hidden_states'].apply(lambda x: x.astype(float))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Confidence Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Confidence model\n",
        "class ConfidenceModel(nn.Module):\n",
        "    def __init__(self, input_size=768, hidden_size=1000, output_size=1):\n",
        "        super(ConfidenceModel, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear3 = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.GELU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.norm = nn.LayerNorm(hidden_size)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "                nn.init.zeros_(m.bias)\n",
        "                                     \n",
        "    def forward(self,x):\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.relu(self.linear2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.sigmoid(self.linear3(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Train, valid and test\n",
        "def train(model, inputs, labels, criterion, optimizer):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs.float())\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return outputs, loss.item()\n",
        "\n",
        "def val(model, inputs, labels, criterion):\n",
        "    model.eval()\n",
        "    outputs = model(inputs.float())\n",
        "    loss = criterion(outputs, labels)\n",
        "    return outputs, loss.item()\n",
        "\n",
        "def test(model, inputs, labels=None, criterion=None):\n",
        "    model.eval()\n",
        "    if labels is None and criterion is None:\n",
        "        outputs = model(inputs.float())\n",
        "        return outputs\n",
        "    else:\n",
        "        outputs = model(inputs.float())\n",
        "        loss = criterion(outputs, labels)\n",
        "        return outputs, loss.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HIDDEN_SIZE = 1000\n",
        "BATCH_SIZE = 4096\n",
        "NUM_SUBGROUPS = 2\n",
        "EPOCHS = 10000\n",
        "PRETRAIN = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DivExplorer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Define abbreviations for plot and visualization\n",
        "from divexplorer.FP_Divergence import abbreviateDict\n",
        "abbreviations = {'Self-reported fluency level=native': 'fluency=native', \\\n",
        "                  'total_silence':'tot_silence', 'location': 'loc', \\\n",
        "                  'Current language used for work/school=English (United States)': 'lang=EN_US', \\\n",
        "                  'speakerId' : 'spkID', \\\n",
        "                  'First Language spoken=English (United States)':  'lang=EN_US', \\\n",
        "                  'trimmed':'trim', \\\n",
        "                  'total_':'', \\\n",
        "                  'speed_rate_word':'speakRate', \\\n",
        "                  'speed_rate_char':'speakCharRate', \\\n",
        "                  'change language': 'change lang', \\\n",
        "                  'duration': 'dur'}\n",
        "\n",
        "abbreviations_shorter = abbreviations.copy()\n",
        "\n",
        "## Function for sorting data cohorts\n",
        "def sortItemset(x, abbreviations={}):\n",
        "    x = list(x)\n",
        "    x.sort()\n",
        "    x = \", \".join(x)\n",
        "    for k, v in abbreviations.items():\n",
        "        x = x.replace(k, v)\n",
        "    return x\n",
        "\n",
        "def attributes_in_itemset(itemset, attributes, alls = True):\n",
        "    \"\"\" Check if attributes are in the itemset (all or at least one)\n",
        "    \n",
        "    Args:\n",
        "        itemset (frozenset): the itemset\n",
        "        attributes (list): list of itemset of interest\n",
        "        alls (bool): If True, check if ALL attributes of the itemset are the input attributes. \n",
        "        If False, check AT LEAST one attribute of the itemset is in the input attributes.\n",
        "        \n",
        "    \"\"\"\n",
        "    # Avoid returning the empty itemset (i.e., info of entire dataset)\n",
        "    if itemset == frozenset() and attributes:\n",
        "        return False\n",
        "    \n",
        "    for item in itemset:\n",
        "        # Get the attribute\n",
        "        attr_i = item.split(\"=\")[0]\n",
        "        \n",
        "        #If True, check if ALL attributes of the itemset are the input attributes.\n",
        "        if alls:\n",
        "            # Check if the attribute is present. If not, the itemset is not admitted\n",
        "            if attr_i not in attributes:\n",
        "                return False\n",
        "        else:\n",
        "            # Check if least one attribute. If yes, return True\n",
        "            if attr_i in attributes:\n",
        "                return True\n",
        "    if alls:\n",
        "        # All attributes of the itemset are indeed admitted\n",
        "        return True\n",
        "    else:\n",
        "        # Otherwise, it means that we find None\n",
        "        return False\n",
        "    \n",
        "def filter_itemset_df_by_attributes(df: pd.DataFrame, attributes: list, alls = True, itemset_col_name: str = \"itemsets\") -> pd.DataFrame:\n",
        "    \"\"\"Get the set of itemsets that have the attributes in the input list (all or at least one)\n",
        "    \n",
        "    Args:\n",
        "        df (pd.DataFrame): the input itemsets (with their info). \n",
        "        attributes (list): list of itemset of interest\n",
        "        alls (bool): If True, check if ALL attributes of the itemset are the input attributes. \n",
        "        If False, check AT LEAST one attribute of the itemset is in the input attributes.\n",
        "        itemset_col_name (str) : the name of the itemset column, \"itemsets\" as default\n",
        "        \n",
        "    Returns:\n",
        "        pd.DataFrame: the set of itemsets (with their info)\n",
        "    \"\"\"\n",
        "\n",
        "    return df.loc[df[itemset_col_name].apply(lambda x: attributes_in_itemset(x, attributes, alls = alls))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Target for DivExplorer: \n",
        "# 'prediction' is 1 if predicted_intet == original_intent, 0 otherwise\n",
        "target_col = 'prediction' \n",
        "target_metric = 'd_posr'\n",
        "target_div = 'd_accuracy'\n",
        "t_value_col = 't_value_tp_fn'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Columns for visualization\n",
        "show_cols = ['support', 'itemsets', '#errors', '#corrects', 'accuracy', \\\n",
        "                'd_accuracy', 't_value', 'support_count', 'length']\n",
        "remapped_cols = {'tn': '#errors', 'tp': '#corrects', 'posr': 'accuracy', \\\n",
        "                target_metric: target_div, 't_value_tp_fn': 't_value'}\n",
        "\n",
        "## Columns of the df file that we are going to analyze \n",
        "demo_cols = ['Self-reported fluency level ', 'First Language spoken',\n",
        "       'Current language used for work/school', 'gender', 'ageRange']\n",
        "\n",
        "slot_cols = ['action', 'object', 'location']\n",
        "\n",
        "signal_cols = ['total_silence', 'total_duration', 'trimmed_duration', \n",
        "       'n_words', 'speed_rate_word', 'speed_rate_word_trimmed']    \n",
        "\n",
        "input_cols = demo_cols + signal_cols + slot_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# select the columns of interest\n",
        "df_divexpl = df[[\n",
        "    'path', 'transcription', \n",
        "    'action', 'object', 'location', \n",
        "    'prediction', \n",
        "    'speakerId', 'gender', 'ageRange', 'Self-reported fluency level ', 'First Language spoken','Current language used for work/school',\n",
        "    'total_silence', 'total_duration', 'trimmed_duration', 'n_words', 'speed_rate_word', 'speed_rate_word_trimmed'\n",
        "    ]]\n",
        "\n",
        "df_valid_divexpl = df_valid[[\n",
        "    'path', 'transcription', \n",
        "    'action', 'object', 'location', \n",
        "    'prediction', \n",
        "    'speakerId', 'gender', 'ageRange', 'Self-reported fluency level ', 'First Language spoken','Current language used for work/school',\n",
        "    'total_silence', 'total_duration', 'trimmed_duration', 'n_words', 'speed_rate_word', 'speed_rate_word_trimmed'\n",
        "    ]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MIN_SUP =       0.03     \n",
        "th_redundancy = 0.05    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Add SpeakerID information if it is present in the df\n",
        "if \"speakerId\" in input_cols:\n",
        "    df_divexpl['speakerId'] = df_divexpl.index.map(lambda x: x.split(\"/\")[2])\n",
        "\n",
        "## Discretize the dataframe\n",
        "from divergence_utils import discretize\n",
        "\n",
        "df_discretized = discretize(\n",
        "    df_divexpl[input_cols+[target_col]],\n",
        "    bins=3,\n",
        "    attributes=input_cols,\n",
        "    strategy=\"quantile\", \n",
        "    round_v = 2,\n",
        "    min_distinct=5,\n",
        ")\n",
        "\n",
        "## Replace values with ranges: \"low\", \"medium\", \"high\"\n",
        "replace_values = {}\n",
        "\n",
        "for i in range(0,len(signal_cols)):\n",
        "\n",
        "    for v in df_discretized[signal_cols[i]].unique():\n",
        "        if \"<=\" == v[0:2]:\n",
        "            replace_values[v] = \"low\"\n",
        "        elif \">\" == v[0]:\n",
        "            replace_values[v] = \"high\"\n",
        "        elif \"(\"  == v[0] and \"]\"  == v[-1]:\n",
        "            replace_values[v] = \"medium\"\n",
        "        else:\n",
        "            raise ValueError(v)\n",
        "\n",
        "    df_discretized[signal_cols[i]].replace(replace_values, inplace=True)\n",
        "    \n",
        "df_discretized.loc[df_discretized[\"location\"]==\"none_location\", \"location\"] = \"none\"\n",
        "df_discretized.loc[df_discretized[\"object\"]==\"none_object\", \"object\"] = \"none\"\n",
        "\n",
        "## Create dict of Divergence df\n",
        "fp_diver = FP_DivergenceExplorer(df_discretized, true_class_name=target_col, class_map={\"P\":1, \"N\":0})\n",
        "FP_fm = fp_diver.getFrequentPatternDivergence(min_support=MIN_SUP, metrics=[target_metric])\n",
        "FP_fm.rename(columns=remapped_cols, inplace=True)\n",
        "FP_fm = FP_fm[show_cols].copy()\n",
        "FP_fm['accuracy'] = round(FP_fm['accuracy'], 5)\n",
        "FP_fm['d_accuracy'] = round(FP_fm['d_accuracy'], 5)\n",
        "FP_fm['t_value'] = round(FP_fm['t_value'], 2)\n",
        "fp_divergence = FP_Divergence(FP_fm, target_div)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Compute the divergence for Wav2Vec2-Base\n",
        "FPdiv = fp_divergence.getDivergence(th_redundancy=th_redundancy)[::-1] #0.05\n",
        "\n",
        "## Retrieve Most Divergent Itemsets \n",
        "from copy import deepcopy\n",
        "pr = FPdiv.copy()\n",
        "pr[\"support\"] = pr[\"support\"].round(2)\n",
        "pr[\"#errors\"] = pr[\"#errors\"].astype(int)\n",
        "pr[\"#corrects\"] = pr[\"#corrects\"].astype(int)\n",
        "pr[\"accuracy\"] = (pr[\"accuracy\"]*100).round(3)\n",
        "pr[\"d_accuracy\"] = (pr[\"d_accuracy\"]*100).round(3)\n",
        "pr.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Create a column in the df, and assign a class to each sample:\n",
        "# - 1 if the sample is in the most divergent itemset\n",
        "# - 2 if the sample is in the second most divergent itemset\n",
        "# - 3 if the sample is in the third most divergent itemset\n",
        "# - ...\n",
        "# - 0 otherwise\n",
        "\n",
        "df_discretized[\"subgID\"] = 0\n",
        "itemsets = []\n",
        "for i in range(NUM_SUBGROUPS):\n",
        "    itemsets.append(list(pr.itemsets.values[i]))\n",
        "for i in tqdm(range(0, len(df_discretized))):\n",
        "    for value,itemset in enumerate(itemsets):\n",
        "        ks = []\n",
        "        vs = []\n",
        "        for item in itemset:\n",
        "            k, v = item.split(\"=\")\n",
        "            ks.append(k)\n",
        "            vs.append(v)\n",
        "        if all(df_discretized.loc[i, ks] == vs):\n",
        "            if df_discretized.loc[i, \"subgID\"] == 0:\n",
        "                df_discretized.loc[i, \"subgID\"] = value+1\n",
        "            else:\n",
        "                continue\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "for i in range(0,NUM_SUBGROUPS+1):\n",
        "    print(len(df_discretized.loc[df_discretized[\"subgID\"]==i]))\n",
        "\n",
        "# df_discretized.to_csv(\"df_discretized.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Add SpeakerID information if it is present in the df\n",
        "if \"speakerId\" in input_cols:\n",
        "    df_valid_divexpl['speakerId'] = df_valid_divexpl.index.map(lambda x: x.split(\"/\")[2])\n",
        "\n",
        "## Discretize the dataframe\n",
        "from divergence_utils import discretize\n",
        "\n",
        "df_discretized_valid = discretize(\n",
        "    df_valid_divexpl[input_cols+[target_col]],\n",
        "    bins=3,\n",
        "    attributes=input_cols,\n",
        "    strategy=\"quantile\", \n",
        "    round_v = 2,\n",
        "    min_distinct=5,\n",
        ")\n",
        "\n",
        "## Replace values with ranges: \"low\", \"medium\", \"high\"\n",
        "replace_values = {}\n",
        "\n",
        "for i in range(0,len(signal_cols)):\n",
        "\n",
        "    for v in df_discretized_valid[signal_cols[i]].unique():\n",
        "        if \"<=\" == v[0:2]:\n",
        "            replace_values[v] = \"low\"\n",
        "        elif \">\" == v[0]:\n",
        "            replace_values[v] = \"high\"\n",
        "        elif \"(\"  == v[0] and \"]\"  == v[-1]:\n",
        "            replace_values[v] = \"medium\"\n",
        "        else:\n",
        "            raise ValueError(v)\n",
        "\n",
        "    df_discretized_valid[signal_cols[i]].replace(replace_values, inplace=True)\n",
        "    \n",
        "df_discretized_valid.loc[df_discretized[\"location\"]==\"none_location\", \"location\"] = \"none\"\n",
        "df_discretized_valid.loc[df_discretized[\"object\"]==\"none_object\", \"object\"] = \"none\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Create a column in the df, and assign a class to each sample:\n",
        "# - 1 if the sample is in the most divergent itemset\n",
        "# - 2 if the sample is in the second most divergent itemset\n",
        "# - 3 if the sample is in the third most divergent itemset\n",
        "# - ...\n",
        "# - 0 otherwise\n",
        "df_discretized_valid[\"subgID\"] = 0\n",
        "for i in tqdm(range(0, len(df_discretized_valid))):\n",
        "    for value,itemset in enumerate(itemsets):\n",
        "        ks = []\n",
        "        vs = []\n",
        "        for item in itemset:\n",
        "            k, v = item.split(\"=\")\n",
        "            ks.append(k)\n",
        "            vs.append(v)\n",
        "        if all(df_discretized_valid.loc[i, ks] == vs):\n",
        "            if df_discretized_valid.loc[i, \"subgID\"] == 0:\n",
        "                df_discretized_valid.loc[i, \"subgID\"] = value+1\n",
        "            else:\n",
        "                continue\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "for i in range(0,NUM_SUBGROUPS+1):\n",
        "    print(len(df_discretized_valid.loc[df_discretized_valid[\"subgID\"]==i]))\n",
        "\n",
        "# df_discretized_valid.to_csv(\"df_discretized_valid.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CM Pretraining and Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if HF == True:\n",
        "    df_cm = df[[\n",
        "        'prediction', \n",
        "        'predicted_action', 'predicted_object', 'predicted_location',\n",
        "        'hidden_states',\n",
        "        'total_silence', 'n_words', 'speed_rate_word'\n",
        "        ]]\n",
        "    df_cm_valid = df_valid[[\n",
        "        'prediction', \n",
        "        'predicted_action', 'predicted_object', 'predicted_location',\n",
        "        'hidden_states',\n",
        "        'total_silence', 'n_words', 'speed_rate_word'\n",
        "        ]]\n",
        "else:\n",
        "    df_cm = df[[\n",
        "        'prediction', \n",
        "        'predicted_intent',\n",
        "        'hidden_states',\n",
        "        'total_silence', 'n_words', 'speed_rate_word'\n",
        "        ]]\n",
        "    df_cm_valid = df_valid[[\n",
        "        'prediction', \n",
        "        'predicted_intent',\n",
        "        'hidden_states',\n",
        "        'total_silence', 'n_words', 'speed_rate_word'\n",
        "        ]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pretraining the CM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Create train and val split\n",
        "if HF == True:\n",
        "    X_train = torch.cat((\n",
        "        torch.tensor(df_cm['predicted_action']),\n",
        "        torch.tensor(df_cm['predicted_object']),\n",
        "        torch.tensor(df_cm['predicted_location']),\n",
        "        torch.stack(\n",
        "            [torch.mean(torch.tensor(el[-1])) for el in df_cm['hidden_states']]\n",
        "            ).unsqueeze(1),\n",
        "        torch.tensor(df_cm['total_silence']).unsqueeze(1),\n",
        "        torch.tensor(df_cm['n_words']).unsqueeze(1),\n",
        "        torch.tensor(df_cm['speed_rate_word']).unsqueeze(1),\n",
        "        ), dim=1)\n",
        "   \n",
        "    X_val = torch.cat((\n",
        "        torch.tensor(df_cm_valid['predicted_action']),\n",
        "        torch.tensor(df_cm_valid['predicted_object']),\n",
        "        torch.tensor(df_cm_valid['predicted_location']),\n",
        "        torch.stack(\n",
        "            [torch.mean(torch.tensor(el[-1])) for el in df_cm_valid['hidden_states']]\n",
        "            ).unsqueeze(1),\n",
        "        torch.tensor(df_cm_valid['total_silence']).unsqueeze(1),\n",
        "        torch.tensor(df_cm_valid['n_words']).unsqueeze(1),\n",
        "        torch.tensor(df_cm_valid['speed_rate_word']).unsqueeze(1),\n",
        "        ), dim=1)\n",
        "\n",
        "else:\n",
        "\n",
        "    X_train = torch.cat((\n",
        "        torch.tensor(df_cm['predicted_intent']),\n",
        "        torch.stack(\n",
        "            [torch.mean(torch.tensor(el[-1])) for el in df_cm['hidden_states']]\n",
        "            ).unsqueeze(1),\n",
        "        torch.tensor(df_cm['total_silence']).unsqueeze(1),\n",
        "        torch.tensor(df_cm['n_words']).unsqueeze(1),\n",
        "        torch.tensor(df_cm['speed_rate_word']).unsqueeze(1),\n",
        "        ), dim=1)\n",
        "   \n",
        "    X_val = torch.cat((\n",
        "        torch.tensor(df_cm_valid['predicted_intent']),\n",
        "        torch.stack(\n",
        "            [torch.mean(torch.tensor(el[-1])) for el in df_cm_valid['hidden_states']]\n",
        "            ).unsqueeze(1),\n",
        "        torch.tensor(df_cm_valid['total_silence']).unsqueeze(1),\n",
        "        torch.tensor(df_cm_valid['n_words']).unsqueeze(1),\n",
        "        torch.tensor(df_cm_valid['speed_rate_word']).unsqueeze(1),\n",
        "        ), dim=1)\n",
        "\n",
        "y_train = torch.tensor(df_cm['prediction']).unsqueeze(1)\n",
        "y_val = torch.tensor(df_cm_valid['prediction']).unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seeds = [1, 10, 42] \n",
        "\n",
        "for seed in seeds:\n",
        "\n",
        "    print(\"Seed: \", seed)\n",
        "    SEED = seed\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "\n",
        "    best_auc = 0\n",
        "    best_acc = 0\n",
        "    best_output = 0\n",
        "    best_model = 0\n",
        "    best_epoch = 0\n",
        "\n",
        "    ## Create model\n",
        "    model = ConfidenceModel(\n",
        "        input_size=X_train.shape[1],\n",
        "        hidden_size=HIDDEN_SIZE, \n",
        "        output_size=1\n",
        "        ).to(device)        \n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.NAdam(model.parameters(), lr=0.005)\n",
        "\n",
        "    ## Train model\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_aucs = []\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "            \n",
        "        ## Train in batches\n",
        "        for i in range(0, len(X_train), BATCH_SIZE):\n",
        "            train_output, train_loss = train(\n",
        "                model, \n",
        "                X_train[i:i+BATCH_SIZE].float().to(device), \n",
        "                y_train[i:i+BATCH_SIZE].float().to(device), \n",
        "                criterion, \n",
        "                optimizer\n",
        "                )\n",
        "        train_losses.append(train_loss)\n",
        "            \n",
        "        ## Validate\n",
        "        val_output, val_loss = val(\n",
        "            model, \n",
        "            X_val.float().to(device), \n",
        "            y_val.float().to(device),\n",
        "            criterion\n",
        "            )\n",
        "        val_losses.append(val_loss)\n",
        "        val_output = (val_output > 0.5).float()\n",
        "        val_acc = accuracy_score(y_val, val_output.cpu().detach().numpy())\n",
        "        val_auc = roc_auc_score(y_val, val_output.cpu().detach().numpy())\n",
        "        val_aucs.append(val_auc)     \n",
        "    \n",
        "        if val_auc > best_auc:\n",
        "            best_auc = val_auc\n",
        "            best_acc = val_acc\n",
        "            best_output = val_output\n",
        "            best_model = model\n",
        "            best_epoch = epoch\n",
        "\n",
        "        # print(\"Epoch: \", epoch, \\\n",
        "        #     \"Train loss: \", round(train_loss, 5), \\\n",
        "        #     \"Val loss: \", round(val_loss, 5), \\\n",
        "        #     \"Val acc: \", round(val_acc*100, 2), \"%\", \\\n",
        "        #     \"Val auc: \", round(val_auc, 2))\n",
        "\n",
        "        if epoch > 150:\n",
        "            if val_losses[-1] > val_losses[-2] and val_losses[-2] > val_losses[-3]:\n",
        "                break\n",
        "\n",
        "    ## Print metrics \n",
        "    print(\"Best epoch: \", best_epoch)\n",
        "    print(\"Val accuracy: \", round(best_acc*100, 2), \"%\")\n",
        "    print(\"Val AUC: \", round(best_auc, 2))\n",
        "\n",
        "    ## Save model\n",
        "    if HF == True:\n",
        "        torch.save(best_model, f'cm_pt_ft/confidence_model_pt_hf.pt')\n",
        "    else:\n",
        "        torch.save(best_model, f'cm_pt_ft/confidence_model_pt.pt')\n",
        "    print(\"Model saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problematic Subgroups Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Create train and val split\n",
        "if HF == True:\n",
        "\n",
        "    X_train = torch.cat((\n",
        "        torch.tensor(df_cm['predicted_action']),\n",
        "        torch.tensor(df_cm['predicted_object']),\n",
        "        torch.tensor(df_cm['predicted_location']),\n",
        "        torch.stack(\n",
        "            [torch.mean(torch.tensor(el[-1])) for el in df_cm['hidden_states']]\n",
        "            ).unsqueeze(1),\n",
        "        torch.tensor(df_cm['total_silence']).unsqueeze(1),\n",
        "        torch.tensor(df_cm['n_words']).unsqueeze(1),\n",
        "        torch.tensor(df_cm['speed_rate_word']).unsqueeze(1),\n",
        "        ), dim=1)\n",
        "\n",
        "    X_val = torch.cat((\n",
        "        torch.tensor(df_cm_valid['predicted_action']),\n",
        "        torch.tensor(df_cm_valid['predicted_object']),\n",
        "        torch.tensor(df_cm_valid['predicted_location']),\n",
        "        torch.stack(\n",
        "            [torch.mean(torch.tensor(el[-1])) for el in df_cm_valid['hidden_states']]\n",
        "            ).unsqueeze(1),\n",
        "        torch.tensor(df_cm_valid['total_silence']).unsqueeze(1),\n",
        "        torch.tensor(df_cm_valid['n_words']).unsqueeze(1),\n",
        "        torch.tensor(df_cm_valid['speed_rate_word']).unsqueeze(1),\n",
        "        ), dim=1)\n",
        "\n",
        "else:\n",
        "\n",
        "    X_train = torch.cat((\n",
        "        torch.tensor(df_cm['predicted_intent']),\n",
        "        torch.stack(\n",
        "            [torch.mean(torch.tensor(el[-1])) for el in df_cm['hidden_states']]\n",
        "            ).unsqueeze(1),\n",
        "        torch.tensor(df_cm['total_silence']).unsqueeze(1),\n",
        "        torch.tensor(df_cm['n_words']).unsqueeze(1),\n",
        "        torch.tensor(df_cm['speed_rate_word']).unsqueeze(1),\n",
        "        ), dim=1)\n",
        "\n",
        "    X_val = torch.cat((\n",
        "        torch.tensor(df_cm_valid['predicted_intent']),\n",
        "        torch.stack(\n",
        "            [torch.mean(torch.tensor(el[-1])) for el in df_cm_valid['hidden_states']]\n",
        "            ).unsqueeze(1),\n",
        "        torch.tensor(df_cm_valid['total_silence']).unsqueeze(1),\n",
        "        torch.tensor(df_cm_valid['n_words']).unsqueeze(1),\n",
        "        torch.tensor(df_cm_valid['speed_rate_word']).unsqueeze(1),\n",
        "        ), dim=1)\n",
        "\n",
        "y_train_subs = torch.tensor(df_discretized['subgID'])\n",
        "y_val_subs = torch.tensor(df_discretized_valid['subgID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seeds = [1, 10, 42] \n",
        "\n",
        "for seed in seeds:\n",
        "\n",
        "    print(\"Seed: \", seed)\n",
        "    SEED = seed\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "\n",
        "    best_f1macro = 0\n",
        "    best_acc = 0\n",
        "    best_output = 0\n",
        "    best_epoch = 0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    if PRETRAIN:\n",
        "        best_model.linear3 = nn.Linear(\n",
        "            HIDDEN_SIZE,\n",
        "            NUM_SUBGROUPS+1\n",
        "            ).to(device)\n",
        "        model = best_model\n",
        "    else:\n",
        "        model = ConfidenceModel(\n",
        "            input_size=X_train.shape[1],\n",
        "            hidden_size=HIDDEN_SIZE,\n",
        "            output_size=NUM_SUBGROUPS+1\n",
        "            ).to(device)\n",
        "\n",
        "    ## Criterion and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.NAdam(model.parameters(), lr=0.005)\n",
        "\n",
        "    ## Train and validate model\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_output, train_loss = train(\n",
        "            model,\n",
        "            X_train.to(device),\n",
        "            y_train_subs.to(device),\n",
        "            criterion,\n",
        "            optimizer\n",
        "            )\n",
        "        val_output, val_loss = val(\n",
        "            model,\n",
        "            X_val.to(device),\n",
        "            y_val_subs.to(device),\n",
        "            criterion\n",
        "            )\n",
        "        val_output = val_output.cpu().detach().numpy()\n",
        "        val_output = np.argmax(val_output, axis=1)\n",
        "        val_acc = accuracy_score(y_val_subs, val_output)\n",
        "        val_f1 = f1_score(y_val_subs, val_output, average='macro')\n",
        "        if val_f1 > best_f1macro:\n",
        "            best_f1macro = val_f1\n",
        "            best_acc = val_acc\n",
        "            best_output = val_output\n",
        "            best_epoch = epoch\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        if epoch > 2000 and val_loss > val_losses[-2] and val_loss > val_losses[-3]:\n",
        "            break\n",
        "\n",
        "    print(\"Best Epoch: \", best_epoch)\n",
        "    print(\"Val Accuracy: \", best_acc)\n",
        "    print(\"Val F1 Macro: \", best_f1macro)\n",
        "    # print(\"Confusion Matrix: \\n\", confusion_matrix(y_val_subs, best_output))\n",
        "    print(\"--------------------\\n\")\n",
        "\n",
        "    ## Save model\n",
        "    if HF == True:\n",
        "        torch.save(model, f'cm_pt_ft/confidence_model_ft_hf.pt')\n",
        "    else:\n",
        "        torch.save(model, f'cm_pt_ft/confidence_model_ft.pt')\n",
        "    print(\"Model saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Select new data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def map_to_array(example, audio_col = 'path'):\n",
        "    speech, _ = librosa.load(example[audio_col], sr=16000, mono=True)\n",
        "    example[\"speech\"] = speech\n",
        "    return example\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = feature_extractor(\n",
        "      examples,\n",
        "      sampling_rate=feature_extractor.sampling_rate, \n",
        "      padding=True, \n",
        "      return_tensors=\"pt\")\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Load model\n",
        "if HF == True:\n",
        "    model_w2v2 = Wav2Vec2ForSequenceClassification.from_pretrained(\"superb/wav2vec2-base-superb-ic\").to(device)\n",
        "else:\n",
        "    model_w2v2 = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
        "        \"fsc_original\", \n",
        "        output_hidden_states=True,\n",
        "        local_files_only=True\n",
        "        ).to(device)\n",
        "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"superb/wav2vec2-base-superb-ic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_left_out = pd.read_csv('data/fsc/train_data_20.csv')\n",
        "\n",
        "dataset_left_out = Dataset.from_pandas(df_left_out)\n",
        "dataset_left_out = dataset_left_out.map(lambda x: map_to_array(x, audio_col='path'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Inference\n",
        "hidden_states_concatenation = []\n",
        "logits_concatenation = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(0, len(dataset_left_out))):\n",
        "        inputs = preprocess_function(dataset_left_out[i][\"speech\"]).to(device)\n",
        "        outputs = model_w2v2(**inputs)\n",
        "        hidden_states_concatenation.append(outputs.hidden_states[-1])\n",
        "        logits_concatenation.append(outputs.logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if HF == True:\n",
        "    torch.save(hidden_states_concatenation, 'pretrained/hidden_states_train_left_out_hf.pt')\n",
        "    torch.save(logits_concatenation, 'pretrained/logits_train_left_out_hf.pt')\n",
        "else:\n",
        "    torch.save(hidden_states_concatenation, 'pretrained/hidden_states_train_left_out.pt')\n",
        "    torch.save(logits_concatenation, 'pretrained/logits_train_left_out.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if HF == True:\n",
        "\n",
        "    ## Actions\n",
        "    action_ids = []\n",
        "    for i in range(len(logits_concatenation)):\n",
        "        logits = logits_concatenation[i].detach().cpu()\n",
        "        action_ids.append(torch.argmax(logits[:, :6], dim=-1).item())\n",
        "    action_labels = [model_w2v2.config.id2label[_id] for _id in action_ids]\n",
        "    action_gt = list(df_left_out['action'].values)\n",
        "    print(\"Action accuracy: \", round(accuracy_score(action_gt, action_labels)*100, 2), \"%\")\n",
        "\n",
        "    ## Objects\n",
        "    object_ids = []\n",
        "    for i in range(len(logits_concatenation)):\n",
        "        logits = logits_concatenation[i].detach().cpu()\n",
        "        object_ids.append(torch.argmax(logits[:, 6:20], dim=-1).item())\n",
        "    object_labels = [model_w2v2.config.id2label[_id + 6] for _id in object_ids]\n",
        "    object_gt = list(df_left_out['object'].values)\n",
        "    object_gt = [f'{x}_object' if x=='none' else x for x in object_gt]\n",
        "    print(\"Obejct accuracy: \", round(accuracy_score(object_gt, object_labels)*100, 2), \"%\")\n",
        "\n",
        "    ## Locations\n",
        "    location_ids = []\n",
        "    for i in range(len(logits_concatenation)):\n",
        "        logits = logits_concatenation[i].detach().cpu()\n",
        "        location_ids.append(torch.argmax(logits[:, 20:24], dim=-1).item())\n",
        "    location_labels = [model_w2v2.config.id2label[_id + 20] for _id in location_ids]\n",
        "    location_gt = list(df_left_out['location'].values)\n",
        "    location_gt = [f'{x}_location' if x=='none' else x for x in location_gt]\n",
        "    print(\"Location accuracy: \", round(accuracy_score(location_gt, location_labels)*100, 2), \"%\")\n",
        "\n",
        "    ## Predictions\n",
        "    intents_predicted = [ action_labels[i]  + \" \" + object_labels[i] + \" \" + location_labels[i] for i in range(0, len(df_left_out))]\n",
        "    intents_gt = [ action_gt[i]  + \" \" + object_gt[i] + \" \" + location_gt[i] for i in range(0, len(df_left_out))]\n",
        "    is_correct = (np.array(intents_predicted) == np.array(intents_gt)).astype(int)\n",
        "    df_left_out['prediction'] = is_correct\n",
        "    print(\"Accuracy: \", round(np.mean(is_correct)*100,2), \"%\")\n",
        "\n",
        "    ## Action, object and location predictions \n",
        "    df_left_out['predicted_action'] = [l[:, :6].detach().cpu().numpy().squeeze() for l in logits_concatenation]\n",
        "    df_left_out['predicted_object'] = [l[:, 6:20].detach().cpu().numpy().squeeze() for l in logits_concatenation]\n",
        "    df_left_out['predicted_location'] = [l[:, 20:24].detach().cpu().numpy().squeeze() for l in logits_concatenation]\n",
        "\n",
        "    ## Hidden states\n",
        "    df_left_out['hidden_states'] = [hs.detach().cpu().numpy().squeeze() for hs in hidden_states_concatenation]\n",
        "    df_left_out['hidden_states'] = df_left_out['hidden_states'].apply(lambda x: x.astype(float))\n",
        "\n",
        "    output_folder = os.path.join(f'data/fsc/fsc_train_20_hf.csv')\n",
        "\n",
        "else:\n",
        "\n",
        "    ## Intents\n",
        "    intents_predicted = []\n",
        "    for i in range(len(logits_concatenation)):\n",
        "        logits = logits_concatenation[i].detach().cpu()\n",
        "        intent = torch.argmax(logits, dim=-1).item()\n",
        "        intents_predicted.append(model_w2v2.config.id2label[intent])\n",
        "    action_gt = list(df_left_out['action'].values)\n",
        "    object_gt = list(df_left_out['object'].values)\n",
        "    location_gt = list(df_left_out['location'].values)\n",
        "    intents_gt = [ action_gt[i]  + \"\" + object_gt[i] + \"\" + location_gt[i] for i in range(0, len(df_left_out))]\n",
        "\n",
        "    ## Predictions\n",
        "    is_correct = (np.array(intents_predicted) == np.array(intents_gt)).astype(int)\n",
        "    df_left_out['prediction'] = is_correct\n",
        "    print(\"Accuracy: \", round(np.mean(is_correct)*100,2), \"%\")\n",
        "\n",
        "    ## Intent predictions\n",
        "    df_left_out['predicted_intent'] = [l.detach().cpu().numpy().squeeze() for l in logits_concatenation]\n",
        "\n",
        "    ## Hidden states\n",
        "    df_left_out['hidden_states'] = [hs.detach().cpu().numpy().squeeze() for hs in hidden_states_concatenation]\n",
        "    df_left_out['hidden_states'] = df_left_out['hidden_states'].apply(lambda x: x.astype(float))\n",
        "\n",
        "    output_folder = os.path.join(f'data/fsc/fsc_train_20.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_left_out.to_csv(output_folder, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discretize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Define abbreviations for plot and visualization\n",
        "from divexplorer.FP_Divergence import abbreviateDict\n",
        "abbreviations = {'Self-reported fluency level=native': 'fluency=native', \\\n",
        "                  'total_silence':'tot_silence', 'location': 'loc', \\\n",
        "                  'Current language used for work/school=English (United States)': 'lang=EN_US', \\\n",
        "                  'speakerId' : 'spkID', \\\n",
        "                  'First Language spoken=English (United States)':  'lang=EN_US', \\\n",
        "                  'trimmed':'trim', \\\n",
        "                  'total_':'', \\\n",
        "                  'speed_rate_word':'speakRate', \\\n",
        "                  'speed_rate_char':'speakCharRate', \\\n",
        "                  'change language': 'change lang', \\\n",
        "                  'duration': 'dur'}\n",
        "\n",
        "abbreviations_shorter = abbreviations.copy()\n",
        "\n",
        "## Function for sorting data cohorts\n",
        "def sortItemset(x, abbreviations={}):\n",
        "    x = list(x)\n",
        "    x.sort()\n",
        "    x = \", \".join(x)\n",
        "    for k, v in abbreviations.items():\n",
        "        x = x.replace(k, v)\n",
        "    return x\n",
        "\n",
        "def attributes_in_itemset(itemset, attributes, alls = True):\n",
        "    \"\"\" Check if attributes are in the itemset (all or at least one)\n",
        "    \n",
        "    Args:\n",
        "        itemset (frozenset): the itemset\n",
        "        attributes (list): list of itemset of interest\n",
        "        alls (bool): If True, check if ALL attributes of the itemset are the input attributes. \n",
        "        If False, check AT LEAST one attribute of the itemset is in the input attributes.\n",
        "        \n",
        "    \"\"\"\n",
        "    # Avoid returning the empty itemset (i.e., info of entire dataset)\n",
        "    if itemset == frozenset() and attributes:\n",
        "        return False\n",
        "    \n",
        "    for item in itemset:\n",
        "        # Get the attribute\n",
        "        attr_i = item.split(\"=\")[0]\n",
        "        \n",
        "        #If True, check if ALL attributes of the itemset are the input attributes.\n",
        "        if alls:\n",
        "            # Check if the attribute is present. If not, the itemset is not admitted\n",
        "            if attr_i not in attributes:\n",
        "                return False\n",
        "        else:\n",
        "            # Check if least one attribute. If yes, return True\n",
        "            if attr_i in attributes:\n",
        "                return True\n",
        "    if alls:\n",
        "        # All attributes of the itemset are indeed admitted\n",
        "        return True\n",
        "    else:\n",
        "        # Otherwise, it means that we find None\n",
        "        return False\n",
        "    \n",
        "def filter_itemset_df_by_attributes(df: pd.DataFrame, attributes: list, alls = True, itemset_col_name: str = \"itemsets\") -> pd.DataFrame:\n",
        "    \"\"\"Get the set of itemsets that have the attributes in the input list (all or at least one)\n",
        "    \n",
        "    Args:\n",
        "        df (pd.DataFrame): the input itemsets (with their info). \n",
        "        attributes (list): list of itemset of interest\n",
        "        alls (bool): If True, check if ALL attributes of the itemset are the input attributes. \n",
        "        If False, check AT LEAST one attribute of the itemset is in the input attributes.\n",
        "        itemset_col_name (str) : the name of the itemset column, \"itemsets\" as default\n",
        "        \n",
        "    Returns:\n",
        "        pd.DataFrame: the set of itemsets (with their info)\n",
        "    \"\"\"\n",
        "\n",
        "    return df.loc[df[itemset_col_name].apply(lambda x: attributes_in_itemset(x, attributes, alls = alls))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Target for DivExplorer: \n",
        "# 'prediction' is 1 if predicted_intent == original_intent, 0 otherwise\n",
        "target_col = 'prediction' \n",
        "target_metric = 'd_posr'\n",
        "target_div = 'd_accuracy'\n",
        "t_value_col = 't_value_tp_fn'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Columns for visualization\n",
        "show_cols = ['support', 'itemsets', '#errors', '#corrects', 'accuracy', \\\n",
        "                'd_accuracy', 't_value', 'support_count', 'length']\n",
        "remapped_cols = {'tn': '#errors', 'tp': '#corrects', 'posr': 'accuracy', \\\n",
        "                target_metric: target_div, 't_value_tp_fn': 't_value'}\n",
        "\n",
        "## Columns of the df file that we are going to analyze \n",
        "demo_cols = ['Self-reported fluency level ', 'First Language spoken',\n",
        "       'Current language used for work/school', 'gender', 'ageRange']\n",
        "\n",
        "slot_cols = ['action', 'object', 'location']\n",
        "\n",
        "signal_cols = ['total_silence', 'total_duration', 'trimmed_duration', \n",
        "       'n_words', 'speed_rate_word', 'speed_rate_word_trimmed']    \n",
        "\n",
        "input_cols = demo_cols + signal_cols + slot_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# select the columns of interest\n",
        "df_left_out_divexpl = df_left_out[[\n",
        "    'path', 'transcription', \n",
        "    'action', 'object', 'location', \n",
        "    'prediction', \n",
        "    'speakerId', 'gender', 'ageRange', 'Self-reported fluency level ', 'First Language spoken','Current language used for work/school',\n",
        "    'total_silence', 'total_duration', 'trimmed_duration', 'n_words', 'speed_rate_word', 'speed_rate_word_trimmed'\n",
        "    ]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Add SpeakerID information if it is present in the df\n",
        "if \"speakerId\" in input_cols:\n",
        "    df_left_out_divexpl['speakerId'] = df_left_out_divexpl.index.map(lambda x: x.split(\"/\")[2])\n",
        "\n",
        "## Discretize the dataframe\n",
        "from divergence_utils import discretize\n",
        "\n",
        "df_discretized_train_left_out = discretize(\n",
        "    df_left_out_divexpl[input_cols+[target_col]],\n",
        "    bins=3,\n",
        "    attributes=input_cols,\n",
        "    strategy=\"quantile\", \n",
        "    round_v = 2,\n",
        "    min_distinct=5,\n",
        ")\n",
        "\n",
        "## Replace values with ranges: \"low\", \"medium\", \"high\"\n",
        "replace_values = {}\n",
        "\n",
        "for i in range(0,len(signal_cols)):\n",
        "\n",
        "    for v in df_discretized_train_left_out[signal_cols[i]].unique():\n",
        "        if \"<=\" == v[0:2]:\n",
        "            replace_values[v] = \"low\"\n",
        "        elif \">\" == v[0]:\n",
        "            replace_values[v] = \"high\"\n",
        "        elif \"(\"  == v[0] and \"]\"  == v[-1]:\n",
        "            replace_values[v] = \"medium\"\n",
        "        else:\n",
        "            raise ValueError(v)\n",
        "\n",
        "    df_discretized_train_left_out[signal_cols[i]].replace(replace_values, inplace=True)\n",
        "\n",
        "df_discretized_train_left_out.loc[df_discretized_train_left_out[\"location\"]==\"none_location\", \"location\"] = \"none\"\n",
        "df_discretized_train_left_out.loc[df_discretized_train_left_out[\"object\"]==\"none_object\", \"object\"] = \"none\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict challenging subgroups IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if HF == True:\n",
        "    X_train_left_out = torch.cat((\n",
        "        torch.tensor(df_left_out['predicted_action']),\n",
        "        torch.tensor(df_left_out['predicted_object']),\n",
        "        torch.tensor(df_left_out['predicted_location']),\n",
        "        torch.stack(\n",
        "            [torch.mean(torch.tensor(el[-1])) for el in df_left_out['hidden_states']]\n",
        "            ).unsqueeze(1),\n",
        "        torch.tensor(df_left_out['total_silence']).unsqueeze(1),\n",
        "        torch.tensor(df_left_out['n_words']).unsqueeze(1),\n",
        "        torch.tensor(df_left_out['speed_rate_word']).unsqueeze(1),\n",
        "        ), dim=1)\n",
        "else:\n",
        "    X_train_left_out = torch.cat((\n",
        "        torch.tensor(df_left_out['predicted_intent']),\n",
        "        torch.stack(\n",
        "            [torch.mean(torch.tensor(el[-1])) for el in df_left_out['hidden_states']]\n",
        "            ).unsqueeze(1),\n",
        "        torch.tensor(df_left_out['total_silence']).unsqueeze(1),\n",
        "        torch.tensor(df_left_out['n_words']).unsqueeze(1),\n",
        "        torch.tensor(df_left_out['speed_rate_word']).unsqueeze(1),\n",
        "        ), dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_left_out_output = test(\n",
        "    model,\n",
        "    X_train_left_out.to(device),\n",
        "    )\n",
        "train_left_out_output = train_left_out_output.cpu().detach().numpy()\n",
        "train_left_out_output = np.argmax(train_left_out_output, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieve the rows in df_left_out for which train_left_out_output is different from 0\n",
        "df_left_out['subgID'] = train_left_out_output\n",
        "print(len(df_left_out))\n",
        "\n",
        "divergent_samples = df_left_out.loc[df_left_out['subgID']!=0]\n",
        "print(len(divergent_samples))\n",
        "\n",
        "divergent_samples = divergent_samples.drop(\n",
        "    columns=['hidden_states', 'predicted_intent', 'prediction', 'subgID']\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_80 = pd.read_csv('data/fsc/train_data_80.csv')\n",
        "print(len(df_train_80))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## concat the datasets df_train_80 and divergent_samples\n",
        "df_new = pd.concat([df_train_80, divergent_samples], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "approach = 'psi'\n",
        "num_samples = len(divergent_samples)\n",
        "\n",
        "df_new.to_csv(f'data/fsc/new_data/train_data_{approach}_k{NUM_SUBGROUPS}_{num_samples}.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Random Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Random baseline: assing each sample a random sample\n",
        "random_pred = np.random.randint(0, NUM_SUBGROUPS+1, len(X_train_left_out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieve the rows in df_left_out for which most_frequent_pred is different from 0\n",
        "df_left_out['subgID'] = random_pred\n",
        "print(len(df_left_out))\n",
        "\n",
        "divergent_samples = df_left_out.loc[df_left_out['subgID']!=0]\n",
        "print(len(divergent_samples))\n",
        "divergent_samples = divergent_samples.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "divergent_samples = divergent_samples[:num_samples]\n",
        "print(len(divergent_samples))\n",
        "\n",
        "divergent_samples = divergent_samples.drop(\n",
        "    columns=['hidden_states', 'predicted_intent', 'prediction', 'subgID']\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## concat the datasets df_train_80 and divergent_samples\n",
        "df_new = pd.concat([df_train_80, divergent_samples], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "approach = 'random'\n",
        "\n",
        "df_new.to_csv(f'data/fsc/new_data/train_data_{approach}_k{NUM_SUBGROUPS}_{num_samples}.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# KNN Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## KNN baseline that assigns each sample to the most frequent class among its k nearest neighbors\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "SEED = 1\n",
        "best_acc = 0\n",
        "best_f1 = 0\n",
        "best_k = 0\n",
        "\n",
        "for k in range(2,10):\n",
        "    \n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train_subs)\n",
        "\n",
        "    knn_pred = knn.predict(X_val)\n",
        "    acc = accuracy_score(y_val_subs, knn_pred)\n",
        "    f1 = f1_score(y_val_subs, knn_pred, average='macro')\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_k = k\n",
        "        best_acc = acc\n",
        "        best_f1 = f1\n",
        "\n",
        "print(\"Best K: \", best_k)\n",
        "print(\"Accuracy: \", best_acc)\n",
        "print(\"F1 Macro: \", best_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn.fit(X_train, y_train_subs)\n",
        "\n",
        "knn_pred = knn.predict(X_train_left_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieve the rows in df_left_out for which knn_pred is different from 0\n",
        "df_left_out['subgID'] = knn_pred\n",
        "print(len(df_left_out))\n",
        "\n",
        "divergent_samples = df_left_out.loc[df_left_out['subgID']!=0]\n",
        "print(len(divergent_samples))\n",
        "divergent_samples = divergent_samples.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "divergent_samples = divergent_samples[:num_samples]\n",
        "print(len(divergent_samples))\n",
        "\n",
        "divergent_samples = divergent_samples.drop(\n",
        "    columns=['hidden_states', 'predicted_intent', 'prediction', 'subgID']\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_80 = pd.read_csv('data/fsc/train_data_80.csv')\n",
        "print(len(df_train_80))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## concat the datasets df_train_80 and divergent_samples\n",
        "df_new = pd.concat([df_train_80, divergent_samples], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "approach = 'knn'\n",
        "\n",
        "df_new.to_csv(f'data/fsc/new_data/train_data_{approach}_k{NUM_SUBGROUPS}_{num_samples}.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CM Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if HF == True:\n",
        "    X_train_left_out = torch.cat((\n",
        "        torch.tensor(df_left_out['predicted_action']),\n",
        "        torch.tensor(df_left_out['predicted_object']),\n",
        "        torch.tensor(df_left_out['predicted_location']),\n",
        "        torch.stack(\n",
        "            [torch.mean(torch.tensor(el[-1])) for el in df_left_out['hidden_states']]\n",
        "            ).unsqueeze(1),\n",
        "        torch.tensor(df_left_out['total_silence']).unsqueeze(1),\n",
        "        torch.tensor(df_left_out['n_words']).unsqueeze(1),\n",
        "        torch.tensor(df_left_out['speed_rate_word']).unsqueeze(1),\n",
        "        ), dim=1)\n",
        "else:\n",
        "    X_train_left_out = torch.cat((\n",
        "        torch.tensor(df_left_out['predicted_intent']),\n",
        "        torch.stack(\n",
        "            [torch.mean(torch.tensor(el[-1])) for el in df_left_out['hidden_states']]\n",
        "            ).unsqueeze(1),\n",
        "        torch.tensor(df_left_out['total_silence']).unsqueeze(1),\n",
        "        torch.tensor(df_left_out['n_words']).unsqueeze(1),\n",
        "        torch.tensor(df_left_out['speed_rate_word']).unsqueeze(1),\n",
        "        ), dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model.linear3 = nn.Linear(HIDDEN_SIZE, NUM_SUBGROUPS+1).to(device)\n",
        "cm_model = best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_left_out_output = test(\n",
        "    cm_model,\n",
        "    X_train_left_out.to(device),\n",
        "    )\n",
        "train_left_out_output = train_left_out_output.cpu().detach().numpy()\n",
        "train_left_out_output = np.argmax(train_left_out_output, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieve the rows in df_left_out for which train_left_out_output is different from 0\n",
        "df_left_out['subgID'] = train_left_out_output\n",
        "print(len(df_left_out))\n",
        "\n",
        "divergent_samples = df_left_out.loc[df_left_out['subgID']!=0]\n",
        "print(len(divergent_samples))\n",
        "\n",
        "divergent_samples = divergent_samples.drop(\n",
        "    columns=['hidden_states', 'predicted_intent', 'prediction', 'subgID']\n",
        "    )\n",
        "divergent_samples = divergent_samples.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "divergent_samples = divergent_samples[:num_samples]\n",
        "print(len(divergent_samples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_80 = pd.read_csv('data/fsc/train_data_80.csv')\n",
        "print(len(df_train_80))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## concat the datasets df_train_80 and divergent_samples\n",
        "df_new = pd.concat([df_train_80, divergent_samples], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "approach = 'cm'\n",
        "\n",
        "df_new.to_csv(f'data/fsc/new_data/train_data_{approach}_k{NUM_SUBGROUPS}_{num_samples}.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Supervised Oracle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HF = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Use the wav2vec2 model to predict the intent of the held out samples\n",
        "# If the prediction is not correct, this sample is considered divergent, thus it is added to the training set\n",
        "\n",
        "## Load model\n",
        "if HF == True:\n",
        "    model_w2v2 = Wav2Vec2ForSequenceClassification.from_pretrained(\"superb/wav2vec2-base-superb-ic\").to(device)\n",
        "else:\n",
        "    model_w2v2 = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
        "        \"fsc_original\", \n",
        "        output_hidden_states=True,\n",
        "        local_files_only=True\n",
        "        ).to(device)\n",
        "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"superb/wav2vec2-base-superb-ic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_left_out = pd.read_csv('data/fsc/train_data_20.csv')\n",
        "dataset_left_out = Dataset.from_pandas(df_left_out)\n",
        "dataset_left_out = dataset_left_out.map(lambda x: map_to_array(x, audio_col='path'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Inference\n",
        "logits_concatenation = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(0, len(dataset_left_out))):\n",
        "        inputs = preprocess_function(dataset_left_out[i][\"speech\"]).to(device)\n",
        "        outputs = model_w2v2(**inputs)\n",
        "        logits_concatenation.append(outputs.logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if HF == True:\n",
        "    \n",
        "        ## Actions\n",
        "        action_ids = []\n",
        "        for i in range(len(logits_concatenation)):\n",
        "            logits = logits_concatenation[i].detach().cpu()\n",
        "            action_ids.append(torch.argmax(logits[:, :6], dim=-1).item())\n",
        "        action_labels = [model_w2v2.config.id2label[_id] for _id in action_ids]\n",
        "        action_gt = list(df_left_out['action'].values)\n",
        "        print(\"Action accuracy: \", round(accuracy_score(action_gt, action_labels)*100, 2), \"%\")\n",
        "    \n",
        "        ## Objects\n",
        "        object_ids = []\n",
        "        for i in range(len(logits_concatenation)):\n",
        "            logits = logits_concatenation[i].detach().cpu()\n",
        "            object_ids.append(torch.argmax(logits[:, 6:20], dim=-1).item())\n",
        "        object_labels = [model_w2v2.config.id2label[_id + 6] for _id in object_ids]\n",
        "        object_gt = list(df_left_out['object'].values)\n",
        "        object_gt = [f'{x}_object' if x=='none' else x for x in object_gt]\n",
        "        print(\"Obejct accuracy: \", round(accuracy_score(object_gt, object_labels)*100, 2), \"%\")\n",
        "    \n",
        "        ## Locations\n",
        "        location_ids = []\n",
        "        for i in range(len(logits_concatenation)):\n",
        "            logits = logits_concatenation[i].detach().cpu()\n",
        "            location_ids.append(torch.argmax(logits[:, 20:24], dim=-1).item())\n",
        "        location_labels = [model_w2v2.config.id2label[_id + 20] for _id in location_ids]\n",
        "        location_gt = list(df_left_out['location'].values)\n",
        "        location_gt = [f'{x}_location' if x=='none' else x for x in location_gt]\n",
        "        print(\"Location accuracy: \", round(accuracy_score(location_gt, location_labels)*100, 2), \"%\")\n",
        "    \n",
        "        ## Predictions\n",
        "        intents_predicted = [ action_labels[i]  + \" \" + object_labels[i] + \" \" + location_labels[i] for i in range(0, len(df_left_out))]\n",
        "        intents_gt = [ action_gt[i]  + \" \" + object_gt[i] + \" \" + location_gt[i] for i in range(0, len(df_left_out))]\n",
        "        is_correct = (np.array(intents_predicted) == np.array(intents_gt)).astype(int)\n",
        "        df_left_out['prediction'] = is_correct\n",
        "        print(\"Accuracy: \", round(np.mean(is_correct)*100,2), \"%\")\n",
        "\n",
        "        ## Action, object and location predictions\n",
        "        df_left_out['predicted_action'] = [l[:, :6].detach().cpu().numpy().squeeze() for l in logits_concatenation]\n",
        "        df_left_out['predicted_object'] = [l[:, 6:20].detach().cpu().numpy().squeeze() for l in logits_concatenation]\n",
        "        df_left_out['predicted_location'] = [l[:, 20:24].detach().cpu().numpy().squeeze() for l in logits_concatenation]\n",
        "\n",
        "\n",
        "else:\n",
        "\n",
        "        ## Intents\n",
        "        intents_predicted = []\n",
        "        for i in range(len(logits_concatenation)):\n",
        "            logits = logits_concatenation[i].detach().cpu()\n",
        "            intent = torch.argmax(logits, dim=-1).item()\n",
        "            intents_predicted.append(model_w2v2.config.id2label[intent])\n",
        "        action_gt = list(df_left_out['action'].values)\n",
        "        object_gt = list(df_left_out['object'].values)\n",
        "        location_gt = list(df_left_out['location'].values)\n",
        "        intents_gt = [ action_gt[i]  + \"\" + object_gt[i] + \"\" + location_gt[i] for i in range(0, len(df_left_out))]\n",
        "\n",
        "        ## Predictions\n",
        "        is_correct = (np.array(intents_predicted) == np.array(intents_gt)).astype(int)\n",
        "        df_left_out['prediction'] = is_correct\n",
        "        print(\"Accuracy: \", round(np.mean(is_correct)*100,2), \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Take only the samples for which the prediction is not correct\n",
        "df_left_out = df_left_out.loc[df_left_out['prediction']==0]\n",
        "print(len(df_left_out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_left_out.to_csv('train_data_20_wrong.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "\n",
        "df_left_out = pd.read_csv('train_data_20_wrong.csv')\n",
        "df = pd.read_csv('data/fsc/train_data_80.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_left_out = df_left_out.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df_left_out = df_left_out[:num_samples]\n",
        "df_new = pd.concat([df, df_left_out], axis=0, ignore_index=True)\n",
        "print(len(df), len(df_left_out), len(df_new))\n",
        "\n",
        "df_new.to_csv(f'data/fsc/new_data/train_data_erroneous_k{K}_{num_samples}.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clustering Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Discretize the dataframe\n",
        "from divergence_utils import discretize\n",
        "\n",
        "df_left_out = pd.read_csv('data/fsc/train_data_20.csv')\n",
        "df_discretized_rest = df_left_out[[f'speech_cluster_id_{k}' for k in [num_clusters]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Number of problematic subgroups: \", NUM_SUBGROUPS)\n",
        "\n",
        "fp_divergence_i = fp_divergence_dict[config]\n",
        "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
        "pr_bot = FPdiv.head(NUM_SUBGROUPS).copy()\n",
        "itemsets = []\n",
        "for i in range(NUM_SUBGROUPS):\n",
        "    itemsets.append(list(pr_bot.itemsets.values[i])[0])\n",
        "\n",
        "## Create a column in the df, and assign a class to each sample:\n",
        "# - 1 if the sample is in the most divergent itemset\n",
        "# - 2 if the sample is in the second most divergent itemset\n",
        "# - 3 if the sample is in the third most divergent itemset\n",
        "# - ...\n",
        "# - 0 otherwise\n",
        "df_discretized_rest[\"subgID\"] = 0\n",
        "for i in range(0, len(df_discretized_rest)):\n",
        "    for value,itemset in enumerate(itemsets):\n",
        "        k, v = itemset.split(\"=\")\n",
        "        if df_discretized_rest.loc[i, k] == int(v):\n",
        "            if df_discretized_rest.loc[i, \"subgID\"] == 0:\n",
        "                df_discretized_rest.loc[i, \"subgID\"] = value+1\n",
        "            else:\n",
        "                continue\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "## Keep in df_discretized_rest only the elements with subgID != 0\n",
        "df_train_rest = pd.read_csv(\"data/fsc/train_data_20.csv\")\n",
        "df_train_rest = df_train_rest.loc[df_discretized_rest[\"subgID\"]!=0][:num_samples]\n",
        "print(\"Total number of samples in to be added: \", len(df_train_rest))\n",
        "\n",
        "## Append df_discretized_rest to df_train\n",
        "df_train = pd.read_csv(\"data/fsc/train_data_80.csv\")\n",
        "df_train = df_train.append(df_train_rest, ignore_index=True)\n",
        "df_train.to_csv(f\"data/fsc/new_data/train_data_clustering_k{NUM_SUBGROUPS}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Metadata Oracle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Discretize the dataframe\n",
        "from divergence_utils import discretize\n",
        "\n",
        "df_left_out = pd.read_csv('data/fsc/train_data_20.csv')\n",
        "\n",
        "df_discretized_rest = discretize(\n",
        "    df_left_out[input_cols],\n",
        "    bins=3,\n",
        "    attributes=input_cols,\n",
        "    strategy=\"quantile\", \n",
        "    round_v = 2,\n",
        "    min_distinct=5,\n",
        ")\n",
        "\n",
        "## Replace values with ranges: \"low\", \"medium\", \"high\"\n",
        "replace_values = {}\n",
        "\n",
        "for i in range(0,len(signal_cols)):\n",
        "\n",
        "    for v in df_discretized_rest[signal_cols[i]].unique():\n",
        "        if \"<=\" == v[0:2]:\n",
        "            replace_values[v] = \"low\"\n",
        "        elif \">\" == v[0]:\n",
        "            replace_values[v] = \"high\"\n",
        "        elif \"(\"  == v[0] and \"]\"  == v[-1]:\n",
        "            replace_values[v] = \"medium\"\n",
        "        else:\n",
        "            raise ValueError(v)\n",
        "\n",
        "    df_discretized_rest[signal_cols[i]].replace(replace_values, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "print(\"Number of problematic subgroups: \", NUM_SUBGROUPS)\n",
        "\n",
        "fp_divergence_i = fp_divergence_dict[config]\n",
        "FPdiv = fp_divergence_i.getDivergence(th_redundancy=th_redundancy)[::-1] \n",
        "pr_bot = FPdiv.head(NUM_SUBGROUPS).copy()\n",
        "itemsets = []\n",
        "for i in range(NUM_SUBGROUPS):\n",
        "    itemsets.append(list(pr_bot.itemsets.values[i]))\n",
        "\n",
        "## Create a column in the df, and assign a class to each sample:\n",
        "# - 1 if the sample is in the most divergent itemset\n",
        "# - 2 if the sample is in the second most divergent itemset\n",
        "# - 3 if the sample is in the third most divergent itemset\n",
        "# - ...\n",
        "# - 0 otherwise\n",
        "df_discretized_rest[\"subgID\"] = 0\n",
        "for i in range(0, len(df_discretized_rest)):\n",
        "    for value,itemset in enumerate(itemsets):\n",
        "        ks = []\n",
        "        vs = []\n",
        "        for item in itemset:\n",
        "            k, v = item.split(\"=\")\n",
        "            ks.append(k)\n",
        "            vs.append(v)\n",
        "        if all(df_discretized_rest.loc[i, ks] == vs):\n",
        "            if df_discretized_rest.loc[i, \"subgID\"] == 0:\n",
        "                df_discretized_rest.loc[i, \"subgID\"] = value+1\n",
        "            else:\n",
        "                continue\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "## Keep in df_discretized_rest only the elements with subgID != 0\n",
        "df_train_rest = pd.read_csv(\"data/fsc/train_data_20.csv\")\n",
        "df_train_rest = df_train_rest.loc[df_discretized_rest[\"subgID\"]!=0][:num_samples]\n",
        "print(\"Total number of samples in to be added: \", len(df_train_rest))\n",
        "\n",
        "## Append df_discretized_rest to df_train\n",
        "df_train = pd.read_csv(\"data/fsc/train_data_80.csv\")\n",
        "df_train = df_train.append(df_train_rest, ignore_index=True)\n",
        "df_train.to_csv(f\"data/fsc/new_data/train_data_metadata_oracle_k{NUM_SUBGROUPS}.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SUPERB - IC Task (FSC).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('amazon': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "a8dce71f01f4cf7d979b7741b7fb8d94cd1b30c77e0541871108952dcff484f0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
